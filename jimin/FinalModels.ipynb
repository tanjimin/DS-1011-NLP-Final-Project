{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dictionaries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pkl.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sentence given numbers\n",
    "def ids2sentence(sentence, dictionary):\n",
    "    return [dictionary[i] for i in sentence]\n",
    "#ids2sentence(en_train_num[0], id2word_en_dic)\n",
    "\n",
    "def add_symbol(id2word_dic, word2id_dic):\n",
    "    symbols = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        id2word_dic[i] = symbol\n",
    "        word2id_dic[symbol] = i\n",
    "    return id2word_dic, word2id_dic\n",
    "\n",
    "id2word_vi_dic = load_zipped_pickle(\"../embeddings/id2word_vi_dic.p\")\n",
    "word2id_vi_dic = load_zipped_pickle(\"../embeddings/word2id_vi_dic.p\")\n",
    "\n",
    "id2word_en_dic = load_zipped_pickle(\"../embeddings/id2word_en_dic.p\")\n",
    "word2id_en_dic = load_zipped_pickle(\"../embeddings/word2id_en_dic.p\")\n",
    "\n",
    "id2word_vi_dic, word2id_vi_dic = add_symbol(id2word_vi_dic, word2id_vi_dic)\n",
    "id2word_en_dic, word2id_en_dic = add_symbol(id2word_en_dic, word2id_en_dic)\n",
    "\n",
    "vi_train = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok.p\")\n",
    "en_train = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok.p\") # Already Processed for symbols\n",
    "\n",
    "vi_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok_num.p\")\n",
    "en_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok_num.p\") # Already Processed for symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by input data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_length(data_input, target_data):\n",
    "    input_size = [len(data) for data in data_input]\n",
    "    size_index = np.argsort(input_size)\n",
    "    return list(np.array(data_input)[size_index]), list(np.array(target_data)[size_index])\n",
    "\n",
    "vi_train_num, en_train_num = sort_by_length(vi_train_num, en_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Data given batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(data, length, max_length):\n",
    "    # Cap maximum length at 100\n",
    "    length = min(max_length, length)\n",
    "    for i, line in enumerate(data):\n",
    "        if len(line) < length:\n",
    "            for i in range(len(line), length):\n",
    "                line.append(0)\n",
    "        else:\n",
    "            data[i] = line[0:length]\n",
    "    return data\n",
    "\n",
    "# Return the batch data and target\n",
    "def get_batch(i, batch_size, train_data, train_target, max_length):\n",
    "    if i * batch_size > len(train_data):\n",
    "        raise Exception('Incorrect batch index')\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = list(np.array(train_data)[start_idx:end_idx])\n",
    "    batch_target = list(np.array(train_target)[start_idx:end_idx])\n",
    "    batch_data = pad(batch_data, len(batch_data[batch_size - 1]), max_length)\n",
    "    max_target = max([len(data) for data in batch_data])\n",
    "    batch_target = pad(batch_target, max_target, max_length)\n",
    "    return batch_data, batch_target\n",
    "\n",
    "# get_batch(5, 64, vi_train_num, en_train_num, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # input_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH FIRST\n",
    "\n",
    "    def forward(self, encoder_input, hidden_input):\n",
    "        # encoder_input: batch * 1 (for 1 word each time)\n",
    "        embedded_input = self.embedding(encoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        # hidden_input: batch * 1(layer) * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, max_len, dropout=0.2,\n",
    "                 num_channels_attn=512, num_channels_conv=512,\n",
    "                 kernel_size=3, num_layers=5):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        self.hidden_size = embedding_size\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.conv = nn.ModuleList([nn.Conv1d(num_channels_conv, num_channels_conv, kernel_size,\n",
    "                                      padding=kernel_size // 2) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, position_ids, sentence_as_wordids):\n",
    "        # Retrieving position and word embeddings\n",
    "        position_embedding = self.position_embedding(position_ids)\n",
    "        word_embedding = self.word_embedding(sentence_as_wordids)\n",
    "        \n",
    "        # Applying dropout to the sum of position + word embeddings\n",
    "        embedded = F.dropout(position_embedding + word_embedding, self.dropout, self.training)\n",
    "        \n",
    "        # Transform the input to be compatible for Conv1d as follows\n",
    "        # Length * Channel ==> Num Batches * Channel * Length\n",
    "        embedded = torch.unsqueeze(embedded.transpose(0, 1), 0)\n",
    "        \n",
    "        # Successive application of convolution layers followed by residual connection\n",
    "        # and non-linearity\n",
    "        \n",
    "        cnn = embedded\n",
    "        for i, layer in enumerate(self.conv):\n",
    "            # layer(cnn) is the convolution operation on the input cnn after which\n",
    "            # we add the original input creating a residual connection\n",
    "            print(cnn.shape)\n",
    "            cnn = F.tanh(layer(cnn)+cnn)        \n",
    "        print(cnn.shape)\n",
    "        return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, batch_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # output_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size,\n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH_FRIST\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1) # Use cross entropy loss outside\n",
    "\n",
    "    def forward(self, decoder_input, hidden_input):\n",
    "        # decoder_input: batch * 1\n",
    "        embedded_input = self.embedding(decoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        embedded_input = F.relu(embedded_input)\n",
    "        # hidden_input: batch * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        output = self.out(output)\n",
    "        # output = self.softmax(output) # not using softmax\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, max_length, batch_size, dropout_p=0.1):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        # Max length for a sentence\n",
    "        self.max_length = max_length\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, \n",
    "                          self.hidden_size,\n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH_FRIST)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, decoder_input, hidden_input, encoder_hiddens):\n",
    "        # hidden_input: 1 * batch * hidden_size\n",
    "        hidden_input = hidden_input.squeeze(0)\n",
    "        # decoder_input: batch * 1\n",
    "        embedded_input = self.embedding(decoder_input)\n",
    "        # embedded_input: batch * 1 * embed_size\n",
    "        embedded_input = self.dropout(embedded_input).squeeze(1)\n",
    "        \n",
    "        # embedded_input: batch * embed_size\n",
    "        # hidden_input: batch * hidden_size \n",
    "        # (Use input and newest hidden to decide which encoder hidden is important)\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded_input, hidden_input), 1)), dim=1).unsqueeze(1)\n",
    "        # encoder_output: max_length * batch * encoder_hidden_size\n",
    "        encoder_hiddens_t = encoder_hiddens.transpose(0, 1)\n",
    "        # attn_weights: batch * 1 * max_length(theoretical)\n",
    "        cropped_attn_weights = attn_weights[:, :, :encoder_hiddens_t.shape[1]]\n",
    "        # cropped_attn_weights: batch * 1 * max_length(actual)\n",
    "        # encoder_hiddens_t: batch * max_length(actual) * encoder_hidden_size\n",
    "        ## \n",
    "        attn_applied = torch.bmm(cropped_attn_weights, encoder_hiddens_t).squeeze(1)\n",
    "        \n",
    "        # embedded_input: batch * embed_size\n",
    "        # attn_applied: batch * encoder_hidden_size\n",
    "        output = torch.cat((embedded_input, attn_applied), 1)\n",
    "        output = self.attn_combine(output)\n",
    "        \n",
    "        # output: batch * hidden_size\n",
    "        gru_input = F.relu(output).unsqueeze(1)\n",
    "        # hidden_input: batch * hidden_size\n",
    "        hidden_input = hidden_input.unsqueeze(0)\n",
    "        # gru_input: batch * 1 * hidden_size\n",
    "        # hidden_input: 1 * batch * hidden_size\n",
    "        output, hidden = self.gru(gru_input, hidden_input)\n",
    "        output = self.out(output)\n",
    "        #output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers,  self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length, use_cnn, use_attention):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Batch\n",
    "    for i in range(len(train_input) // batch_size):\n",
    "        loss = 0\n",
    "        \n",
    "        batch = get_batch(i, batch_size, train_input, train_target, max_length)\n",
    "        # size batch_size * seq_length\n",
    "        batch_input = torch.tensor(batch[0], device=device)\n",
    "        batch_target = torch.tensor(batch[1], device=device)\n",
    "        input_length = batch_input.shape[1]\n",
    "        target_length = batch_target.shape[1]\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(input_length, batch_size, 1, encoder.hidden_size, device=device)\n",
    "        encoder_hiddens = torch.zeros(input_length, 1, batch_size, encoder.hidden_size, device=device)\n",
    "        \n",
    "        # Encode\n",
    "        encoder_hidden = None\n",
    "        \n",
    "        if use_cnn:\n",
    "            position_ids = torch.LongTensor(range(0, input_length), device=device)\n",
    "            #encoder_outputs = encoder()\n",
    "            encoder_hiddens = encoder(position_ids, batch_input)\n",
    "        else:\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            for ec_idx in range(input_length):\n",
    "                # input batch_size * 1\n",
    "                encoder_output, encoder_hidden = encoder(batch_input[:, ec_idx].unsqueeze(1), encoder_hidden)\n",
    "                encoder_outputs[ec_idx] = encoder_output\n",
    "                encoder_hiddens[ec_idx] = encoder_hidden\n",
    "        \n",
    "        # Decode\n",
    "        decoder_hidden = None\n",
    "        if use_cnn:\n",
    "            decoder_hidden = decoder.initHidden()\n",
    "        else:\n",
    "            decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.tensor([2] * batch_size, device=device) # SOS token 2\n",
    "        \n",
    "        \n",
    "        ## Print Value\n",
    "        sample_sentence = []\n",
    "        \n",
    "        # Always use Teacher Forcing\n",
    "        for dc_idx in range(target_length):\n",
    "            if use_attention: \n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input.unsqueeze(1), decoder_hidden, encoder_hiddens.squeeze(1))\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input.unsqueeze(1), decoder_hidden)\n",
    "            decoder_output = decoder_output.squeeze(1) # get rid of the seq dimention\n",
    "            loss += criterion(decoder_output, batch_target[:, dc_idx])\n",
    "            decoder_input = batch_target[:, dc_idx]\n",
    "            \n",
    "            if i % 1 == 0:\n",
    "                ## Print Value\n",
    "                sample_sentence.append(torch.argmax(decoder_output[0]).item())\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            s = int(time.time() - start_time)\n",
    "            m = math.floor(s / 60)\n",
    "            s = s - m * 60\n",
    "            print('Time: ', m, 'mins', s, 'seconds' , ' Training Loss: ', loss.item() / target_length, 'Progress: ', round(i / (len(train_input) // batch_size) * 100, 2), '%')\n",
    "            if i % 1 == 0:\n",
    "                print(\"Predict: \", ids2sentence(sample_sentence, id2word_en_dic))\n",
    "                print(\"Actual: \", ids2sentence(batch_target[0].cpu().numpy(), id2word_en_dic))\n",
    "        \n",
    "    print('Training Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dic_size_vi = len(id2word_vi_dic.keys())\n",
    "dic_size_en = len(id2word_en_dic.keys())\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "max_length = 100\n",
    "\n",
    "## Add ignore index\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#encoder = EncoderRNN(input_size = dic_size_vi, hidden_size = hidden_size, num_layers = 1, batch_size = batch_size).to(device)\n",
    "#decoder = DecoderRNN(hidden_size = hidden_size, output_size = dic_size_en, num_layers = 1, batch_size = batch_size).to(device)\n",
    "\n",
    "encoder = pkl.load(open(\"./model/encoder.p\", \"rb\"))\n",
    "decoder = pkl.load(open(\"./model/decoder.p\", \"rb\"))\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(50):\n",
    "    train(vi_train_num, en_train_num, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length)\n",
    "    if i % 2 == 0:\n",
    "        pkl.dump(encoder, open(\"./model/encoder.p\", \"wb\"))\n",
    "        pkl.dump(decoder, open(\"./model/decoder.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size_vi = len(id2word_vi_dic.keys())\n",
    "dic_size_en = len(id2word_en_dic.keys())\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "max_length = 100\n",
    "\n",
    "## Add ignore index\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "encoder = EncoderRNN(input_size = dic_size_vi, hidden_size = hidden_size, num_layers = 1, batch_size = batch_size).to(device)\n",
    "decoder = AttentionDecoderRNN(hidden_size = hidden_size, output_size = dic_size_en, num_layers = 1, max_length = max_length, batch_size = batch_size, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0 mins 0 seconds  Training Loss:  11.510273742675782 Progress:  0.0 %\n",
      "Predict:  ['thrash', 'physiotherapist', 'growths', 'benefice', 'logical', 'riverine', 'sunscreens', 'Fergus', 'ripping', 'vain']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  9.280722045898438 Progress:  0.0 %\n",
      "Predict:  ['<sos>', '<sos>', '<sos>', '<sos>', 'these', 'notes', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  4.904550170898437 Progress:  0.0 %\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'notes', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  1.6712812423706054 Progress:  0.0 %\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.4696480751037598 Progress:  0.0 %\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.243605899810791 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.13130269050598145 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.09440178871154785 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.05451879501342773 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.036969661712646484 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.026824951171875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.019005203247070314 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.014142704010009766 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.010765552520751953 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.008464241027832031 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0070591926574707035 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.005884552001953125 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.004948997497558593 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.004169178009033203 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0035154342651367186 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.003039264678955078 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0026086807250976563 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.002252674102783203 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.001972866058349609 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00177154541015625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0015649795532226562 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0014318466186523438 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0012948036193847657 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.001195526123046875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0010969161987304688 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.001023101806640625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0009570121765136719 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0008984565734863281 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0008370399475097657 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0 mins 0 seconds  Training Loss:  0.0007944107055664062 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0007666587829589844 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0007195472717285156 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0006924629211425781 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0006590843200683594 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0006361007690429688 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0006140708923339844 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005964279174804687 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005743026733398438 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005573272705078125 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005423545837402344 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005323410034179688 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00051727294921875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000507354736328125 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0005001068115234375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00048274993896484374 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004773139953613281 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00046710968017578126 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000457000732421875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004511833190917969 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004454612731933594 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00043878555297851565 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004337310791015625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00042409896850585936 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000418853759765625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004143714904785156 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0004116058349609375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00040607452392578126 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00040302276611328127 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003981590270996094 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003932952880859375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000390625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003857612609863281 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0 mins 0 seconds  Training Loss:  0.0003936767578125 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003780364990234375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003757476806640625 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00037059783935546877 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000368499755859375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003673553466796875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00036306381225585936 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003612518310546875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003558158874511719 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003550529479980469 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003518104553222656 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003495216369628906 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00034723281860351565 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00034351348876953124 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.000341796875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00033702850341796873 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00033578872680664065 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003340721130371094 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003302574157714844 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003289222717285156 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003265380859375 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003233909606933594 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00032100677490234377 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003207206726074219 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003154754638671875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003154754638671875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003124237060546875 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00031147003173828127 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00030775070190429686 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.0003060340881347656 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00030508041381835935 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Time:  0 mins 0 seconds  Training Loss:  0.00030269622802734373 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0 mins 0 seconds  Training Loss:  0.0003008842468261719 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "overfit_vi_train = vi_train_num[10000:10002]\n",
    "overfit_en_train = en_train_num[10000:10002]\n",
    "\n",
    "for i in range(100):\n",
    "    train(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length = max_length,use_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit_vi_train = vi_train_num[10000:10002]\n",
    "# overfit_en_train = en_train_num[10000:10002]\n",
    "\n",
    "# for i in range(100):\n",
    "#     train(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size_vi = len(id2word_vi_dic.keys())\n",
    "dic_size_en = len(id2word_en_dic.keys())\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "batch_size = 2\n",
    "max_length = 100\n",
    "\n",
    "## Add ignore index\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "encoder = ConvEncoder(vocab_size = dic_size_vi, embedding_size = hidden_size, max_len=max_length, dropout=0.2, num_channels_attn=512, num_channels_conv=512)\n",
    "decoder = AttentionDecoderRNN(hidden_size = hidden_size, output_size = dic_size_en, num_layers = 1, max_length = max_length, batch_size = batch_size, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 2, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [512, 512, 3], but got input of size [1, 10, 2, 256] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fff6e0d257e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_vi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_en_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cnn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-b319334c862b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length, use_cnn, use_attention)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mposition_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#encoder_outputs = encoder()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mencoder_hiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-bf6c997f1743>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, position_ids, sentence_as_wordids)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# we add the original input creating a residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 176\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [512, 512, 3], but got input of size [1, 10, 2, 256] instead"
     ]
    }
   ],
   "source": [
    "overfit_vi_train = vi_train_num[10000:10002]\n",
    "overfit_en_train = en_train_num[10000:10002]\n",
    "\n",
    "for i in range(100):\n",
    "    train(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length = max_length, use_cnn= True, use_attention = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
