{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dictionaries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pkl.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sentence given numbers\n",
    "def ids2sentence(sentence, dictionary):\n",
    "    return [dictionary[i] for i in sentence]\n",
    "#ids2sentence(en_train_num[0], id2word_en_dic)\n",
    "\n",
    "def add_symbol(id2word_dic, word2id_dic):\n",
    "    symbols = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        id2word_dic[i] = symbol\n",
    "        word2id_dic[symbol] = i\n",
    "    return id2word_dic, word2id_dic\n",
    "\n",
    "id2word_vi_dic = load_zipped_pickle(\"../embeddings/id2word_vi_dic.p\")\n",
    "word2id_vi_dic = load_zipped_pickle(\"../embeddings/word2id_vi_dic.p\")\n",
    "\n",
    "id2word_en_dic = load_zipped_pickle(\"../embeddings/id2word_en_dic.p\")\n",
    "word2id_en_dic = load_zipped_pickle(\"../embeddings/word2id_en_dic.p\")\n",
    "\n",
    "id2word_vi_dic, word2id_vi_dic = add_symbol(id2word_vi_dic, word2id_vi_dic)\n",
    "id2word_en_dic, word2id_en_dic = add_symbol(id2word_en_dic, word2id_en_dic)\n",
    "\n",
    "vi_train = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok.p\")\n",
    "en_train = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok.p\") # Already Processed for symbols\n",
    "\n",
    "vi_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok_num.p\")\n",
    "en_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok_num.p\") # Already Processed for symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by input data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_length(data_input, target_data):\n",
    "    input_size = [len(data) for data in data_input]\n",
    "    size_index = np.argsort(input_size)\n",
    "    return list(np.array(data_input)[size_index]), list(np.array(target_data)[size_index])\n",
    "\n",
    "vi_train_num, en_train_num = sort_by_length(vi_train_num, en_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Data given batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(data, length):\n",
    "    # Cap maximum length at 100\n",
    "    length = min(100, length)\n",
    "    for i, line in enumerate(data):\n",
    "        if len(line) < length:\n",
    "            for i in range(len(line), length):\n",
    "                line.append(0)\n",
    "        else:\n",
    "            data[i] = line[0:length]\n",
    "    return data\n",
    "\n",
    "# Return the batch data and target\n",
    "def get_batch(i, batch_size, train_data, train_target):\n",
    "    if i * batch_size > len(train_data):\n",
    "        raise Exception('Incorrect batch index')\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = list(np.array(train_data)[start_idx:end_idx])\n",
    "    batch_target = list(np.array(train_target)[start_idx:end_idx])\n",
    "    batch_data = pad(batch_data, len(batch_data[batch_size - 1]))\n",
    "    max_target = max([len(data) for data in batch_data])\n",
    "    batch_target = pad(batch_target, max_target)\n",
    "    return batch_data, batch_target\n",
    "\n",
    "# get_batch(5, 64, vi_train_num, en_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # input_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH FIRST\n",
    "\n",
    "    def forward(self, encoder_input, hidden_input):\n",
    "        # encoder_input: batch * 1 (for 1 word each time)\n",
    "        embedded_input = self.embedding(encoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        # hidden_input: batch * 1(layer) * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, batch_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # output_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size,\n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH_FRIST\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1) # Use cross entropy loss outside\n",
    "\n",
    "    def forward(self, decoder_input, hidden_input):\n",
    "        # decoder_input: batch * 1\n",
    "        embedded_input = self.embedding(decoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        embedded_input = F.relu(embedded_input)\n",
    "        # hidden_input: batch * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        output = self.out(output)\n",
    "        # output = self.softmax(output) # not using softmax\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Batch\n",
    "    for i in range(len(train_input) // batch_size):\n",
    "        loss = 0\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        batch = get_batch(i, batch_size, train_input, train_target)\n",
    "        # size batch_size * seq_length\n",
    "        batch_input = torch.tensor(batch[0], device=device)\n",
    "        batch_target = torch.tensor(batch[1], device=device)\n",
    "        input_length = batch_input.shape[1] ## should be seq length\n",
    "        target_length = batch_target.shape[1]\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(input_length, batch_size, 1, 256, device=device)\n",
    "        encoder_hiddens = torch.zeros(input_length, 1, batch_size, 256, device=device)\n",
    "        \n",
    "        # Encode\n",
    "        for ec_idx in range(input_length):\n",
    "            # input batch_size * 1\n",
    "            encoder_output, encoder_hidden = encoder(batch_input[:, ec_idx].unsqueeze(1), encoder_hidden)\n",
    "            encoder_outputs[ec_idx] = encoder_output\n",
    "            encoder_hiddens[ec_idx] = encoder_hidden\n",
    "        \n",
    "        # Decode\n",
    "        decoder_input = torch.tensor([2] * batch_size, device=device) # SOS token 2\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        ## Print Value\n",
    "        sample_sentence = []\n",
    "        \n",
    "        # Always use Teacher Forcing\n",
    "        for dc_idx in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input.unsqueeze(1), decoder_hidden)\n",
    "            decoder_output = decoder_output.squeeze(1) # get rid of the seq dimention\n",
    "            loss += criterion(decoder_output, batch_target[:, dc_idx])\n",
    "            decoder_input = batch_target[:, dc_idx]\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                ## Print Value\n",
    "                sample_sentence.append(torch.argmax(decoder_output[0]).item())\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            s = int(time.time() - start_time)\n",
    "            m = math.floor(s / 60)\n",
    "            s = s - m * 60\n",
    "            print('Time: ', m, 'mins', s, 'seconds' , ' Training Loss: ', loss.item() / target_length, 'Progress: ', round(i / (len(train_input) // batch_size) * 100, 2), '%')\n",
    "            if i % 200 == 0:\n",
    "                print(\"Predict: \", ids2sentence(sample_sentence, id2word_en_dic))\n",
    "                print(\"Actual: \", ids2sentence(batch_target[0].cpu().numpy(), id2word_en_dic))\n",
    "        \n",
    "    print('Training Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_size_vi = len(id2word_vi_dic.keys())\n",
    "dic_size_en = len(id2word_en_dic.keys())\n",
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "\n",
    "## Add ignore index\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#encoder = EncoderRNN(input_size = dic_size_vi, hidden_size = hidden_size, num_layers = 1, batch_size = batch_size).to(device)\n",
    "#decoder = DecoderRNN(hidden_size = hidden_size, output_size = dic_size_en, num_layers = 1, batch_size = batch_size).to(device)\n",
    "\n",
    "encoder = pkl.load(open(\"./model/encoder.p\", \"rb\"))\n",
    "decoder = pkl.load(open(\"./model/decoder.p\", \"rb\"))\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimin/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel/__main__.py:19: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/jimin/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel/__main__.py:21: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0 mins 0 seconds  Training Loss:  8.157244682312012 Progress:  0.0 %\n",
      "Predict:  ['<sos>', 'the']\n",
      "Actual:  ['<sos>', '<eos>']\n",
      "Time:  0 mins 9 seconds  Training Loss:  2.1544600895472934 Progress:  2.4 %\n",
      "Time:  0 mins 18 seconds  Training Loss:  2.984735276963976 Progress:  4.8 %\n",
      "Time:  0 mins 27 seconds  Training Loss:  2.839649200439453 Progress:  7.2 %\n",
      "Time:  0 mins 36 seconds  Training Loss:  2.814463806152344 Progress:  9.6 %\n",
      "Predict:  ['<sos>', 'and', 'i', 'm', 'walking', 'to', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'and', 'i', 'was', 'thrilled', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  0 mins 45 seconds  Training Loss:  2.8500487587668677 Progress:  12.0 %\n",
      "Time:  0 mins 55 seconds  Training Loss:  2.8859275182088218 Progress:  14.4 %\n",
      "Time:  1 mins 4 seconds  Training Loss:  2.8084589640299478 Progress:  16.8 %\n",
      "Time:  1 mins 14 seconds  Training Loss:  2.781269366924579 Progress:  19.2 %\n",
      "Predict:  ['<sos>', 'the', 'same', 'is', 'the', 'of', 'the', 'little', 'of', 'the', 'little', '.', '.']\n",
      "Actual:  ['<sos>', 'the', 'house', 'is', 'sort', 'of', 'a', 'distortion', 'of', 'a', 'square', 'block', '.']\n",
      "Time:  1 mins 24 seconds  Training Loss:  3.085954121180943 Progress:  21.6 %\n",
      "Time:  1 mins 34 seconds  Training Loss:  2.8466453552246094 Progress:  24.0 %\n",
      "Time:  1 mins 43 seconds  Training Loss:  2.992207336425781 Progress:  26.4 %\n",
      "Time:  1 mins 53 seconds  Training Loss:  2.980999755859375 Progress:  28.8 %\n",
      "Predict:  ['<sos>', 'women', 'woman', 'woman', ',', 'a', 'just', 'woman', 'of', 'women', '.', '.', '<eos>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'her', 'virginity', 'statement', 'was', 'not', 'a', 'piece', 'of', 'wishful', 'thinking', '.', '<eos>', '<pad>', '<pad>']\n",
      "Time:  2 mins 2 seconds  Training Loss:  2.953540802001953 Progress:  31.2 %\n",
      "Time:  2 mins 12 seconds  Training Loss:  3.1223205117618336 Progress:  33.61 %\n",
      "Time:  2 mins 22 seconds  Training Loss:  3.321032131419462 Progress:  36.01 %\n",
      "Time:  2 mins 32 seconds  Training Loss:  3.0693431430392795 Progress:  38.41 %\n",
      "Predict:  ['<sos>', 'i', 'think', ',', 's', 'a', ',', ',', 'i', 'to', 'the', '.', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'i', 'think', 'it', 'was', 'that', 'interaction', 'that', 'led', 'to', 'personal', 'computing', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  2 mins 42 seconds  Training Loss:  3.263519889429996 Progress:  40.81 %\n",
      "Time:  2 mins 52 seconds  Training Loss:  3.260873794555664 Progress:  43.21 %\n",
      "Time:  3 mins 2 seconds  Training Loss:  3.264046478271484 Progress:  45.61 %\n",
      "Time:  3 mins 13 seconds  Training Loss:  3.3248839605422247 Progress:  48.01 %\n",
      "Predict:  ['<sos>', 'and', 'i', 'm', 'try', 'to', 'a', 'job', 'to', 'get', 'a', 'decision', 'to', 'a', 'good', 'job', '.', 'the', '.', 'injustice', 'job']\n",
      "Actual:  ['<sos>', 'or', 'i', 'could', 'negotiate', 'with', 'my', 'employer', 'to', 'make', 'that', 'decision', 'in', 'the', 'best', 'interest', 'of', 'myself', 'and', 'my', 'company']\n",
      "Time:  3 mins 23 seconds  Training Loss:  3.2895871942693535 Progress:  50.41 %\n",
      "Time:  3 mins 34 seconds  Training Loss:  3.2955113286557407 Progress:  52.81 %\n",
      "Time:  3 mins 45 seconds  Training Loss:  3.509235699971517 Progress:  55.21 %\n",
      "Time:  3 mins 56 seconds  Training Loss:  3.653746337890625 Progress:  57.61 %\n",
      "Predict:  ['<sos>', 'now', ',', 'about', 'something', ',', 'and', ',', ',', 'and', 'changes', 'reveal', 'never', '.', 'the', 'heart', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'now', 'think', 'about', 'that', '.', 'south', 'africa', ',', 'terrible', 'atrocities', 'had', 'happened', 'in', 'the', 'society', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  4 mins 8 seconds  Training Loss:  3.448193770188552 Progress:  60.01 %\n",
      "Time:  4 mins 20 seconds  Training Loss:  3.5475537335431135 Progress:  62.41 %\n",
      "Time:  4 mins 32 seconds  Training Loss:  3.271644047328404 Progress:  64.81 %\n",
      "Time:  4 mins 45 seconds  Training Loss:  3.3702855603448274 Progress:  67.21 %\n",
      "Predict:  ['<sos>', 'and', 'we', 'realized', 'that', 'unlike', 'course', ',', 'we', 'is', 'is', 'not', 'not', 'failing', 'in', 'the', 'world', '.', 'stage', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'and', 'i', 'realized', ',', 'of', 'course', ',', 'this', 'dialogue', 'is', 'definitely', 'not', 'occurring', 'in', 'the', 'public', 'at', 'large', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  4 mins 58 seconds  Training Loss:  3.505659484863281 Progress:  69.61 %\n",
      "Time:  5 mins 12 seconds  Training Loss:  3.4848310947418213 Progress:  72.01 %\n",
      "Time:  5 mins 26 seconds  Training Loss:  3.6714815081972065 Progress:  74.41 %\n",
      "Time:  5 mins 40 seconds  Training Loss:  3.5091914585658484 Progress:  76.81 %\n",
      "Predict:  ['<sos>', 'but', 'so', 'he', ',', 'was', ',', 'me', ',', 'i', 's', 'die', 'be', 'a', ',', 'but', 'i', 'i', 'die', 'that', 'a', ',', 'city', ',', 'because', 'have', 'die', '.', 'the', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'and', 'then', 'afterwards', 'he', 'said', 'to', 'me', ',', 'it', 'will', 'always', 'be', 'difficult', ',', 'but', 'if', 'you', 'cry', 'like', 'this', 'every', 'time', ',', 'you', 'will', 'die', 'of', 'heartbreak', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  5 mins 55 seconds  Training Loss:  3.716111466691301 Progress:  79.21 %\n",
      "Time:  6 mins 10 seconds  Training Loss:  3.506223629682492 Progress:  81.61 %\n",
      "Time:  6 mins 26 seconds  Training Loss:  3.6743182670779344 Progress:  84.01 %\n",
      "Time:  6 mins 44 seconds  Training Loss:  3.5793380737304688 Progress:  86.41 %\n",
      "Predict:  ['<sos>', 'but', 'the', 'end', 'time', ',', 'we', ',', 'we', 'can', 'a', 'the', 'a', 'as', ',', 'a', 'cost', 'that', 'the', 'to', 'a', 'the', ',', 'to', 'the', 'the', ',', 'and', 'we', 'are', 'illegal', 'functioning', 'response', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'at', 'the', 'same', 'time', ',', 'though', ',', 'we', 'spend', 'about', 'as', 'much', 'money', 'taking', 'the', 'smells', 'off', 'us', 'as', 'putting', 'them', 'back', 'on', 'in', 'perfumes', ',', 'and', 'perfumes', 'are', 'a', 'multi-billion-dollar', 'business', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  7 mins 1 seconds  Training Loss:  3.7529231943982713 Progress:  88.81 %\n",
      "Time:  7 mins 20 seconds  Training Loss:  3.7085523418351714 Progress:  91.21 %\n",
      "Time:  7 mins 40 seconds  Training Loss:  3.8161746911835253 Progress:  93.61 %\n",
      "Time:  8 mins 2 seconds  Training Loss:  3.7369659423828123 Progress:  96.02 %\n",
      "Predict:  ['<sos>', 'i', 'm', 'i', 'i', 'learn', 'about', 'about', 'i', 'i', 'what', 'to', 'historian', 'cultures', ',', ',', 'i', 'm', 'wanted', 'to', 'learn', ',', 'i', 'you', 'learn', 'it', 'that', 'the', 'world', ',', 'a', 'learn', ',', 'be', ',', 'of', ',', 'the', 'about', ',', 'the', 'world', 'world', ',', 's', ',', '.', 'the', 'bit', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Actual:  ['<sos>', 'i', 'hope', 'when', 'you', 'learn', 'things', ',', 'like', 'about', 'how', 'the', 'natural', 'world', 'works', '--', 'i', 'just', 'want', 'to', 'say', 'that', 'whenever', 'you', 'read', 'something', 'in', 'the', 'newspaper', 'or', 'you', 'get', 'to', 'hear', 'some', 'talk', 'about', 'something', 'ridiculous', 'in', 'the', 'natural', 'world', 'it', 'was', 'done', 'by', 'a', 'child', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Time:  8 mins 27 seconds  Training Loss:  3.9823718702936746 Progress:  98.42 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e8188328207a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/encoder.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/decoder.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9b05c2555187>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0msample_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    train(vi_train_num, en_train_num, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)\n",
    "    if i % 2 == 0:\n",
    "        pkl.dump(encoder, open(\"./model/encoder.p\", \"wb\"))\n",
    "        pkl.dump(decoder, open(\"./model/decoder.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit_vi_train = vi_train_num[10000:10002]\n",
    "# overfit_en_train = en_train_num[10000:10002]\n",
    "\n",
    "# for i in range(100):\n",
    "#     train(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
