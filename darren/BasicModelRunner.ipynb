{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BasicModel\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from utils import asMinutes, timeSince, load_zipped_pickle, corpus_bleu, directories\n",
    "from langUtils import loadLangPairs, langDataset, langCollateFn, initHybridEmbeddings, tensorToList\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "zh, en = loadLangPairs(\"zh\")\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = langDataset([(zh.train_num[i], en.train_num[i]) for i in range(len(zh.train_num)) if (len(zh.train[i]) < zh.max_length) & (len(en.train[i]) < en.max_length)])\n",
    "# overfit_dataset = langDataset([(zh.train_num[i], en.train_num[i]) for i in range(32)])\n",
    "# overfit_loader = torch.utils.data.DataLoader(dataset=overfit_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=langCollateFn,\n",
    "#                                            shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)\n",
    "dev_dataset = langDataset([(zh.dev_num[i], en.dev_num[i]) for i in range(len(zh.dev_num)) if (len(zh.dev[i]) < zh.max_length) & (len(en.dev[i]) < en.max_length)])\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "## Add ignore index\n",
    "zh_criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "zh_encoder = BasicModel.EncoderRNN(input_size = zh.n_words, hidden_size = HIDDEN_SIZE, num_layers = 1, batch_size = BATCH_SIZE, raw_emb=zh.emb, learn_ids=zh.learn_ids).to(device)\n",
    "zh_decoder = BasicModel.DecoderRNN(hidden_size = HIDDEN_SIZE, output_size = en.n_words, num_layers = 1, batch_size = BATCH_SIZE, raw_emb=en.emb, learn_ids=en.learn_ids).to(device)\n",
    "\n",
    "zh_encoder_optimizer = optim.Adam(zh_encoder.parameters(), lr=learning_rate)\n",
    "zh_decoder_optimizer = optim.Adam(zh_decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_SYMBOLS_ID = PAD_ID, UNK_ID, SOS_ID, EOS_ID = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_loader, dev_loader, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, epochs, print_every, hidden_size):\n",
    "    start = time.time()\n",
    "    print('Initializing Model Training + Eval...')\n",
    "    losses = []\n",
    "    train_scores = []\n",
    "    dev_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(train_loader):\n",
    "            if (len(inp[0]) != batch_size):\n",
    "                continue\n",
    "            inp.transpose_(0,1)\n",
    "            output.transpose_(0,1)\n",
    "            inp = inp.to(device)\n",
    "            output = output.to(device)\n",
    "            loss += BasicModel.train(inp, output, out_max, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, hidden_size)\n",
    "            if i % print_every == 0 and i > 0:\n",
    "                losses.append(loss/i)\n",
    "                print(\"Time Elapsed: {} | Loss: {:.4}\".format(asMinutes(time.time() - start),\n",
    "                                                                                loss/i))\n",
    "                pkl.dump(encoder, open(\"./zh-g-base-encoder-adam0.01.p\", \"wb\"))\n",
    "                pkl.dump(decoder, open(\"./zh-g-base-decoder-adam0.01.p\", \"wb\"))\n",
    "        train_score = BasicModel.bleuEval(encoder, decoder, train_loader, batch_size, hidden_size)\n",
    "        train_scores.append(train_score)\n",
    "        print(\"Epoch: {} | Time Elapsed: {} | Loss: {:.4} | Train BLEU: {:.4}\".format(epoch + 1, \n",
    "                                                                                                        asMinutes(time.time() - start),\n",
    "                                                                                                        loss/len(train_loader), \n",
    "                                                                                                        train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model Training + Eval...\n",
      "Time Elapsed: 4m 39s | Loss: 5.744\n",
      "Time Elapsed: 9m 18s | Loss: 5.521\n",
      "Time Elapsed: 13m 58s | Loss: 5.418\n",
      "Time Elapsed: 18m 40s | Loss: 5.279\n",
      "Time Elapsed: 23m 20s | Loss: 5.179\n",
      "Time Elapsed: 28m 0s | Loss: 5.101\n",
      "Time Elapsed: 32m 39s | Loss: 5.05\n",
      "Time Elapsed: 37m 19s | Loss: 5.003\n",
      "Time Elapsed: 42m 3s | Loss: 4.962\n",
      "Time Elapsed: 46m 45s | Loss: 4.932\n",
      "Time Elapsed: 51m 26s | Loss: 4.902\n",
      "Time Elapsed: 56m 4s | Loss: 4.875\n",
      "Time Elapsed: 60m 45s | Loss: 4.846\n",
      "Time Elapsed: 65m 27s | Loss: 4.821\n",
      "Time Elapsed: 70m 6s | Loss: 4.8\n",
      "Time Elapsed: 74m 47s | Loss: 4.781\n",
      "Time Elapsed: 79m 24s | Loss: 4.761\n",
      "Time Elapsed: 83m 57s | Loss: 4.742\n",
      "Epoch: 1 | Time Elapsed: 90m 59s | Loss: 4.738 | Train BLEU: 1.116\n",
      "Time Elapsed: 94m 15s | Loss: 4.287\n",
      "Time Elapsed: 97m 34s | Loss: 4.276\n",
      "Time Elapsed: 100m 50s | Loss: 4.276\n",
      "Time Elapsed: 104m 53s | Loss: 4.277\n",
      "Time Elapsed: 109m 32s | Loss: 4.268\n",
      "Time Elapsed: 114m 11s | Loss: 4.256\n",
      "Time Elapsed: 118m 52s | Loss: 4.25\n",
      "Time Elapsed: 123m 30s | Loss: 4.243\n",
      "Time Elapsed: 128m 9s | Loss: 4.236\n",
      "Time Elapsed: 132m 46s | Loss: 4.228\n",
      "Time Elapsed: 137m 27s | Loss: 4.22\n",
      "Time Elapsed: 142m 7s | Loss: 4.212\n",
      "Time Elapsed: 146m 46s | Loss: 4.208\n",
      "Time Elapsed: 151m 26s | Loss: 4.203\n",
      "Time Elapsed: 156m 4s | Loss: 4.197\n",
      "Time Elapsed: 160m 46s | Loss: 4.192\n",
      "Time Elapsed: 165m 24s | Loss: 4.188\n",
      "Time Elapsed: 169m 50s | Loss: 4.184\n",
      "Epoch: 2 | Time Elapsed: 178m 15s | Loss: 4.181 | Train BLEU: 1.194\n",
      "Time Elapsed: 182m 50s | Loss: 3.941\n",
      "Time Elapsed: 187m 32s | Loss: 3.946\n",
      "Time Elapsed: 192m 11s | Loss: 3.953\n",
      "Time Elapsed: 195m 31s | Loss: 3.959\n",
      "Time Elapsed: 198m 47s | Loss: 3.962\n",
      "Time Elapsed: 202m 3s | Loss: 3.964\n",
      "Time Elapsed: 205m 20s | Loss: 3.968\n",
      "Time Elapsed: 208m 37s | Loss: 3.97\n",
      "Time Elapsed: 213m 1s | Loss: 3.974\n",
      "Time Elapsed: 217m 42s | Loss: 3.976\n",
      "Time Elapsed: 222m 23s | Loss: 3.978\n",
      "Time Elapsed: 227m 3s | Loss: 3.98\n",
      "Time Elapsed: 231m 42s | Loss: 3.981\n",
      "Time Elapsed: 236m 21s | Loss: 3.983\n",
      "Time Elapsed: 240m 59s | Loss: 3.984\n",
      "Time Elapsed: 245m 37s | Loss: 3.985\n",
      "Time Elapsed: 250m 14s | Loss: 3.986\n",
      "Time Elapsed: 254m 37s | Loss: 3.986\n",
      "Epoch: 3 | Time Elapsed: 263m 28s | Loss: 3.985 | Train BLEU: 1.077\n",
      "Time Elapsed: 268m 6s | Loss: 3.819\n",
      "Time Elapsed: 272m 44s | Loss: 3.825\n",
      "Time Elapsed: 277m 22s | Loss: 3.833\n",
      "Time Elapsed: 282m 1s | Loss: 3.843\n",
      "Time Elapsed: 286m 38s | Loss: 3.849\n",
      "Time Elapsed: 291m 18s | Loss: 3.853\n",
      "Time Elapsed: 295m 58s | Loss: 3.858\n",
      "Time Elapsed: 299m 59s | Loss: 3.861\n",
      "Time Elapsed: 303m 15s | Loss: 3.865\n",
      "Time Elapsed: 306m 32s | Loss: 3.869\n",
      "Time Elapsed: 309m 46s | Loss: 3.872\n",
      "Time Elapsed: 313m 1s | Loss: 3.874\n",
      "Time Elapsed: 316m 57s | Loss: 3.877\n",
      "Time Elapsed: 321m 35s | Loss: 3.88\n",
      "Time Elapsed: 326m 14s | Loss: 3.886\n",
      "Time Elapsed: 330m 55s | Loss: 3.897\n",
      "Time Elapsed: 335m 34s | Loss: 3.902\n",
      "Time Elapsed: 339m 47s | Loss: 3.904\n",
      "Epoch: 4 | Time Elapsed: 348m 56s | Loss: 3.903 | Train BLEU: 2.19\n",
      "Time Elapsed: 353m 34s | Loss: 3.758\n",
      "Time Elapsed: 358m 12s | Loss: 3.753\n",
      "Time Elapsed: 362m 55s | Loss: 3.763\n",
      "Time Elapsed: 367m 38s | Loss: 3.773\n",
      "Time Elapsed: 372m 22s | Loss: 3.781\n",
      "Time Elapsed: 377m 3s | Loss: 3.788\n",
      "Time Elapsed: 381m 44s | Loss: 3.792\n",
      "Time Elapsed: 386m 24s | Loss: 3.798\n",
      "Time Elapsed: 391m 3s | Loss: 3.802\n",
      "Time Elapsed: 395m 43s | Loss: 3.806\n",
      "Time Elapsed: 400m 24s | Loss: 3.81\n",
      "Time Elapsed: 405m 3s | Loss: 3.815\n",
      "Time Elapsed: 408m 20s | Loss: 3.818\n",
      "Time Elapsed: 411m 38s | Loss: 3.823\n",
      "Time Elapsed: 414m 57s | Loss: 3.826\n",
      "Time Elapsed: 418m 15s | Loss: 3.828\n",
      "Time Elapsed: 421m 34s | Loss: 3.831\n",
      "Time Elapsed: 425m 23s | Loss: 3.833\n",
      "Epoch: 5 | Time Elapsed: 435m 18s | Loss: 3.832 | Train BLEU: 1.086\n",
      "Time Elapsed: 439m 59s | Loss: 3.678\n",
      "Time Elapsed: 444m 40s | Loss: 3.687\n",
      "Time Elapsed: 449m 21s | Loss: 3.702\n",
      "Time Elapsed: 454m 3s | Loss: 3.707\n",
      "Time Elapsed: 458m 43s | Loss: 3.718\n",
      "Time Elapsed: 463m 26s | Loss: 3.724\n",
      "Time Elapsed: 468m 7s | Loss: 3.733\n",
      "Time Elapsed: 472m 48s | Loss: 3.74\n",
      "Time Elapsed: 477m 27s | Loss: 3.746\n",
      "Time Elapsed: 482m 6s | Loss: 3.752\n",
      "Time Elapsed: 486m 47s | Loss: 3.757\n",
      "Time Elapsed: 491m 25s | Loss: 3.762\n",
      "Time Elapsed: 496m 5s | Loss: 3.767\n",
      "Time Elapsed: 500m 44s | Loss: 3.772\n",
      "Time Elapsed: 505m 22s | Loss: 3.775\n",
      "Time Elapsed: 510m 0s | Loss: 3.778\n",
      "Time Elapsed: 513m 47s | Loss: 3.781\n",
      "Time Elapsed: 516m 15s | Loss: 3.785\n",
      "Epoch: 6 | Time Elapsed: 524m 24s | Loss: 3.784 | Train BLEU: 1.077\n",
      "Time Elapsed: 529m 2s | Loss: 3.624\n",
      "Time Elapsed: 533m 40s | Loss: 3.632\n",
      "Time Elapsed: 538m 18s | Loss: 3.651\n",
      "Time Elapsed: 542m 53s | Loss: 3.665\n",
      "Time Elapsed: 547m 31s | Loss: 3.675\n",
      "Time Elapsed: 552m 6s | Loss: 3.683\n",
      "Time Elapsed: 556m 47s | Loss: 3.691\n",
      "Time Elapsed: 561m 23s | Loss: 3.699\n",
      "Time Elapsed: 566m 1s | Loss: 3.704\n",
      "Time Elapsed: 570m 40s | Loss: 3.71\n",
      "Time Elapsed: 575m 19s | Loss: 3.715\n",
      "Time Elapsed: 579m 58s | Loss: 3.72\n",
      "Time Elapsed: 584m 37s | Loss: 3.724\n",
      "Time Elapsed: 589m 14s | Loss: 3.73\n",
      "Time Elapsed: 593m 52s | Loss: 3.734\n",
      "Time Elapsed: 598m 32s | Loss: 3.738\n",
      "Time Elapsed: 602m 20s | Loss: 3.743\n",
      "Time Elapsed: 605m 43s | Loss: 3.747\n",
      "Epoch: 7 | Time Elapsed: 612m 1s | Loss: 3.746 | Train BLEU: 2.259\n",
      "Time Elapsed: 615m 16s | Loss: 3.599\n",
      "Time Elapsed: 618m 33s | Loss: 3.614\n",
      "Time Elapsed: 623m 12s | Loss: 3.622\n",
      "Time Elapsed: 627m 50s | Loss: 3.632\n",
      "Time Elapsed: 632m 27s | Loss: 3.638\n",
      "Time Elapsed: 637m 5s | Loss: 3.647\n",
      "Time Elapsed: 641m 42s | Loss: 3.656\n",
      "Time Elapsed: 646m 20s | Loss: 3.662\n",
      "Time Elapsed: 650m 59s | Loss: 3.67\n",
      "Time Elapsed: 655m 35s | Loss: 3.676\n",
      "Time Elapsed: 660m 14s | Loss: 3.682\n",
      "Time Elapsed: 664m 51s | Loss: 3.687\n",
      "Time Elapsed: 669m 30s | Loss: 3.691\n",
      "Time Elapsed: 674m 7s | Loss: 3.696\n",
      "Time Elapsed: 678m 44s | Loss: 3.7\n",
      "Time Elapsed: 683m 21s | Loss: 3.705\n",
      "Time Elapsed: 687m 58s | Loss: 3.71\n",
      "Time Elapsed: 691m 24s | Loss: 3.716\n",
      "Epoch: 8 | Time Elapsed: 702m 2s | Loss: 3.715 | Train BLEU: 1.305\n",
      "Time Elapsed: 706m 40s | Loss: 3.56\n",
      "Time Elapsed: 710m 4s | Loss: 3.584\n",
      "Time Elapsed: 713m 20s | Loss: 3.597\n",
      "Time Elapsed: 716m 35s | Loss: 3.61\n",
      "Time Elapsed: 719m 50s | Loss: 3.619\n",
      "Time Elapsed: 723m 3s | Loss: 3.627\n",
      "Time Elapsed: 727m 21s | Loss: 3.633\n",
      "Time Elapsed: 732m 0s | Loss: 3.639\n",
      "Time Elapsed: 736m 36s | Loss: 3.645\n",
      "Time Elapsed: 741m 14s | Loss: 3.652\n",
      "Time Elapsed: 745m 54s | Loss: 3.658\n",
      "Time Elapsed: 750m 33s | Loss: 3.664\n",
      "Time Elapsed: 755m 12s | Loss: 3.67\n",
      "Time Elapsed: 759m 50s | Loss: 3.675\n",
      "Time Elapsed: 764m 28s | Loss: 3.68\n",
      "Time Elapsed: 769m 8s | Loss: 3.685\n",
      "Time Elapsed: 773m 30s | Loss: 3.691\n",
      "Time Elapsed: 776m 54s | Loss: 3.695\n",
      "Epoch: 9 | Time Elapsed: 787m 14s | Loss: 3.694 | Train BLEU: 0.8682\n",
      "Time Elapsed: 791m 50s | Loss: 3.553\n",
      "Time Elapsed: 796m 29s | Loss: 3.557\n",
      "Time Elapsed: 801m 9s | Loss: 3.572\n",
      "Time Elapsed: 805m 51s | Loss: 3.587\n",
      "Time Elapsed: 810m 30s | Loss: 3.599\n",
      "Time Elapsed: 814m 19s | Loss: 3.61\n",
      "Time Elapsed: 817m 37s | Loss: 3.617\n",
      "Time Elapsed: 820m 54s | Loss: 3.623\n",
      "Time Elapsed: 824m 12s | Loss: 3.629\n",
      "Time Elapsed: 827m 29s | Loss: 3.634\n",
      "Time Elapsed: 831m 23s | Loss: 3.64\n",
      "Time Elapsed: 836m 5s | Loss: 3.646\n",
      "Time Elapsed: 840m 45s | Loss: 3.653\n",
      "Time Elapsed: 845m 26s | Loss: 3.658\n",
      "Time Elapsed: 850m 3s | Loss: 3.663\n",
      "Time Elapsed: 854m 43s | Loss: 3.669\n",
      "Time Elapsed: 859m 8s | Loss: 3.674\n",
      "Time Elapsed: 862m 32s | Loss: 3.678\n",
      "Epoch: 10 | Time Elapsed: 873m 27s | Loss: 3.677 | Train BLEU: 3.206\n",
      "Time Elapsed: 878m 7s | Loss: 3.546\n",
      "Time Elapsed: 882m 45s | Loss: 3.554\n",
      "Time Elapsed: 887m 25s | Loss: 3.557\n",
      "Time Elapsed: 892m 4s | Loss: 3.567\n",
      "Time Elapsed: 896m 44s | Loss: 3.578\n",
      "Time Elapsed: 901m 24s | Loss: 3.587\n",
      "Time Elapsed: 906m 4s | Loss: 3.596\n",
      "Time Elapsed: 910m 44s | Loss: 3.604\n",
      "Time Elapsed: 915m 22s | Loss: 3.613\n",
      "Time Elapsed: 919m 27s | Loss: 3.618\n",
      "Time Elapsed: 922m 44s | Loss: 3.625\n",
      "Time Elapsed: 926m 2s | Loss: 3.632\n",
      "Time Elapsed: 929m 21s | Loss: 3.638\n",
      "Time Elapsed: 932m 37s | Loss: 3.644\n",
      "Time Elapsed: 936m 13s | Loss: 3.65\n",
      "Time Elapsed: 940m 51s | Loss: 3.655\n",
      "Time Elapsed: 944m 53s | Loss: 3.66\n",
      "Time Elapsed: 948m 18s | Loss: 3.664\n",
      "Epoch: 11 | Time Elapsed: 959m 24s | Loss: 3.663 | Train BLEU: 1.626\n",
      "Time Elapsed: 964m 3s | Loss: 3.543\n",
      "Time Elapsed: 968m 42s | Loss: 3.544\n",
      "Time Elapsed: 973m 23s | Loss: 3.551\n",
      "Time Elapsed: 978m 1s | Loss: 3.563\n",
      "Time Elapsed: 982m 43s | Loss: 3.575\n",
      "Time Elapsed: 987m 21s | Loss: 3.581\n",
      "Time Elapsed: 992m 2s | Loss: 3.587\n",
      "Time Elapsed: 996m 41s | Loss: 3.595\n",
      "Time Elapsed: 1001m 20s | Loss: 3.602\n",
      "Time Elapsed: 1005m 58s | Loss: 3.611\n",
      "Time Elapsed: 1010m 39s | Loss: 3.618\n",
      "Time Elapsed: 1015m 16s | Loss: 3.624\n",
      "Time Elapsed: 1019m 53s | Loss: 3.628\n",
      "Time Elapsed: 1024m 17s | Loss: 3.64\n",
      "Time Elapsed: 1027m 34s | Loss: 3.65\n",
      "Time Elapsed: 1030m 49s | Loss: 3.655\n",
      "Time Elapsed: 1033m 29s | Loss: 3.661\n",
      "Time Elapsed: 1035m 55s | Loss: 3.665\n",
      "Epoch: 12 | Time Elapsed: 1049m 5s | Loss: 3.664 | Train BLEU: 1.98\n",
      "Time Elapsed: 1053m 42s | Loss: 3.499\n",
      "Time Elapsed: 1058m 22s | Loss: 3.518\n",
      "Time Elapsed: 1063m 1s | Loss: 3.53\n",
      "Time Elapsed: 1067m 38s | Loss: 3.543\n",
      "Time Elapsed: 1072m 16s | Loss: 3.57\n",
      "Time Elapsed: 1076m 54s | Loss: 3.582\n",
      "Time Elapsed: 1081m 33s | Loss: 3.587\n",
      "Time Elapsed: 1086m 13s | Loss: 3.594\n",
      "Time Elapsed: 1090m 52s | Loss: 3.599\n",
      "Time Elapsed: 1095m 32s | Loss: 3.605\n",
      "Time Elapsed: 1100m 11s | Loss: 3.611\n",
      "Time Elapsed: 1104m 50s | Loss: 3.617\n",
      "Time Elapsed: 1109m 28s | Loss: 3.623\n",
      "Time Elapsed: 1114m 7s | Loss: 3.628\n",
      "Time Elapsed: 1118m 47s | Loss: 3.633\n",
      "Time Elapsed: 1122m 25s | Loss: 3.637\n",
      "Time Elapsed: 1125m 13s | Loss: 3.643\n",
      "Time Elapsed: 1127m 30s | Loss: 3.648\n",
      "Epoch: 13 | Time Elapsed: 1138m 47s | Loss: 3.647 | Train BLEU: 4.233\n",
      "Time Elapsed: 1143m 26s | Loss: 3.51\n",
      "Time Elapsed: 1148m 4s | Loss: 3.513\n",
      "Time Elapsed: 1152m 44s | Loss: 3.53\n",
      "Time Elapsed: 1157m 24s | Loss: 3.536\n",
      "Time Elapsed: 1162m 4s | Loss: 3.548\n",
      "Time Elapsed: 1166m 43s | Loss: 3.559\n",
      "Time Elapsed: 1171m 20s | Loss: 3.567\n",
      "Time Elapsed: 1175m 59s | Loss: 3.573\n",
      "Time Elapsed: 1180m 37s | Loss: 3.582\n",
      "Time Elapsed: 1185m 16s | Loss: 3.59\n",
      "Time Elapsed: 1189m 53s | Loss: 3.597\n",
      "Time Elapsed: 1194m 31s | Loss: 3.603\n"
     ]
    }
   ],
   "source": [
    "fit(train_loader, dev_loader, zh_encoder, zh_decoder, zh_encoder_optimizer, zh_decoder_optimizer, zh_criterion, BATCH_SIZE, 15, 300, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9743f68e9bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ^output got cut off due to accidentally exiting jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
