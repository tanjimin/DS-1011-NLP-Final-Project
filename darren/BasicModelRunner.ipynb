{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BasicModel\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from utils import asMinutes, timeSince, load_zipped_pickle, corpus_bleu, directories\n",
    "from langUtils import loadLangPairs, langDataset, langCollateFn, initHybridEmbeddings, tensorToList\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "zh, en = loadLangPairs(\"zh\")\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = langDataset([(zh.train_num[i], en.train_num[i]) for i in range(len(zh.train_num)) if (len(zh.train[i]) < zh.max_length) & (len(en.train[i]) < en.max_length)])\n",
    "# overfit_dataset = langDataset([(zh.train_num[i], en.train_num[i]) for i in range(32)])\n",
    "# overfit_loader = torch.utils.data.DataLoader(dataset=overfit_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=langCollateFn,\n",
    "#                                            shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)\n",
    "dev_dataset = langDataset([(zh.dev_num[i], en.dev_num[i]) for i in range(len(zh.dev_num)) if (len(zh.dev[i]) < zh.max_length) & (len(en.dev[i]) < en.max_length)])\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "## Add ignore index\n",
    "zh_criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "zh_encoder = BasicModel.EncoderRNN(input_size = zh.n_words, hidden_size = HIDDEN_SIZE, num_layers = 1, batch_size = BATCH_SIZE, raw_emb=zh.emb, learn_ids=zh.learn_ids).to(device)\n",
    "zh_decoder = BasicModel.DecoderRNN(hidden_size = HIDDEN_SIZE, output_size = en.n_words, num_layers = 1, batch_size = BATCH_SIZE, raw_emb=en.emb, learn_ids=en.learn_ids).to(device)\n",
    "\n",
    "zh_encoder_optimizer = optim.Adam(zh_encoder.parameters(), lr=learning_rate)\n",
    "zh_decoder_optimizer = optim.Adam(zh_decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_loader, dev_loader, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, epochs, print_every, hidden_size):\n",
    "    start = time.time()\n",
    "    print('Initializing Model Training + Eval...')\n",
    "    losses = []\n",
    "    train_scores = []\n",
    "    dev_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(train_loader):\n",
    "            if (len(inp[0]) != batch_size):\n",
    "                continue\n",
    "            inp.transpose_(0,1)\n",
    "            output.transpose_(0,1)\n",
    "            inp = inp.to(device)\n",
    "            output = output.to(device)\n",
    "            loss += BasicModel.train(inp, output, out_max, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, hidden_size)\n",
    "            if i % print_every == 0 and i > 0:\n",
    "                losses.append(loss/i)\n",
    "                print(\"Time Elapsed: {} | Loss: {:.4}\".format(asMinutes(time.time() - start),\n",
    "                                                                                loss/i))\n",
    "        train_score = BasicModel.bleuEval(encoder, decoder, train_loader, batch_size, hidden_size)\n",
    "        dev_score = BasicModel.bleuEval(encoder, decoder, dev_loader, batch_size, hidden_size)\n",
    "        train_scores.append(train_score)\n",
    "        dev_scores.append(dev_score)\n",
    "        print(\"Epoch: {} | Time Elapsed: {} | Loss: {:.4} | Train BLEU: {:.4} | Dev BLEU: {:.4}\".format(epoch + 1 + 10, \n",
    "                                                                                                        asMinutes(time.time() - start),\n",
    "                                                                                                        loss/len(train_loader), \n",
    "                                                                                                        train_score, \n",
    "                                                                                                        dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model Training + Eval...\n",
      "Time Elapsed: 3m 3s | Loss: 5.481\n",
      "Time Elapsed: 5m 32s | Loss: 5.095\n",
      "Time Elapsed: 7m 27s | Loss: 4.896\n",
      "Time Elapsed: 9m 23s | Loss: 4.769\n",
      "Time Elapsed: 11m 44s | Loss: 4.679\n",
      "Time Elapsed: 14m 50s | Loss: 4.609\n",
      "Time Elapsed: 17m 56s | Loss: 4.552\n",
      "Time Elapsed: 21m 0s | Loss: 4.508\n",
      "Time Elapsed: 24m 6s | Loss: 4.468\n",
      "Time Elapsed: 27m 11s | Loss: 4.435\n",
      "Time Elapsed: 30m 16s | Loss: 4.408\n",
      "Time Elapsed: 33m 22s | Loss: 4.384\n",
      "Time Elapsed: 36m 25s | Loss: 4.362\n",
      "Time Elapsed: 39m 31s | Loss: 4.342\n",
      "Time Elapsed: 42m 36s | Loss: 4.323\n",
      "Time Elapsed: 45m 41s | Loss: 4.306\n",
      "Time Elapsed: 48m 47s | Loss: 4.291\n",
      "Time Elapsed: 51m 51s | Loss: 4.277\n",
      "Epoch: 11 | Time Elapsed: 59m 46s | Loss: 4.274 | Train BLEU: 2.297 | Dev BLEU: 2.004\n",
      "Time Elapsed: 62m 52s | Loss: 3.9\n",
      "Time Elapsed: 65m 57s | Loss: 3.883\n",
      "Time Elapsed: 69m 2s | Loss: 3.886\n",
      "Time Elapsed: 72m 8s | Loss: 3.892\n",
      "Time Elapsed: 74m 49s | Loss: 3.892\n",
      "Time Elapsed: 76m 46s | Loss: 3.893\n",
      "Time Elapsed: 78m 41s | Loss: 3.89\n",
      "Time Elapsed: 80m 50s | Loss: 3.893\n",
      "Time Elapsed: 83m 54s | Loss: 3.894\n",
      "Time Elapsed: 86m 59s | Loss: 3.895\n",
      "Time Elapsed: 90m 5s | Loss: 3.897\n",
      "Time Elapsed: 93m 9s | Loss: 3.898\n",
      "Time Elapsed: 96m 14s | Loss: 3.898\n",
      "Time Elapsed: 99m 19s | Loss: 3.897\n",
      "Time Elapsed: 102m 24s | Loss: 3.898\n",
      "Time Elapsed: 105m 28s | Loss: 3.9\n",
      "Time Elapsed: 108m 33s | Loss: 3.899\n",
      "Time Elapsed: 111m 38s | Loss: 3.9\n",
      "Epoch: 12 | Time Elapsed: 119m 36s | Loss: 3.899 | Train BLEU: 1.878 | Dev BLEU: 1.384\n",
      "Time Elapsed: 122m 41s | Loss: 3.736\n",
      "Time Elapsed: 125m 46s | Loss: 3.73\n",
      "Time Elapsed: 128m 51s | Loss: 3.734\n",
      "Time Elapsed: 131m 57s | Loss: 3.74\n",
      "Time Elapsed: 135m 1s | Loss: 3.746\n",
      "Time Elapsed: 138m 5s | Loss: 3.755\n",
      "Time Elapsed: 141m 9s | Loss: 3.759\n",
      "Time Elapsed: 143m 59s | Loss: 3.762\n",
      "Time Elapsed: 145m 54s | Loss: 3.766\n",
      "Time Elapsed: 147m 51s | Loss: 3.772\n",
      "Time Elapsed: 149m 51s | Loss: 3.774\n",
      "Time Elapsed: 152m 55s | Loss: 3.776\n",
      "Time Elapsed: 156m 0s | Loss: 3.779\n",
      "Time Elapsed: 159m 4s | Loss: 3.78\n",
      "Time Elapsed: 162m 9s | Loss: 3.783\n",
      "Time Elapsed: 165m 14s | Loss: 3.784\n",
      "Time Elapsed: 168m 19s | Loss: 3.786\n",
      "Time Elapsed: 171m 24s | Loss: 3.788\n",
      "Epoch: 13 | Time Elapsed: 179m 18s | Loss: 3.787 | Train BLEU: 2.101 | Dev BLEU: 2.417\n",
      "Time Elapsed: 182m 23s | Loss: 3.643\n",
      "Time Elapsed: 185m 28s | Loss: 3.644\n",
      "Time Elapsed: 188m 33s | Loss: 3.655\n",
      "Time Elapsed: 191m 38s | Loss: 3.661\n",
      "Time Elapsed: 194m 45s | Loss: 3.667\n",
      "Time Elapsed: 197m 51s | Loss: 3.671\n",
      "Time Elapsed: 200m 56s | Loss: 3.675\n",
      "Time Elapsed: 204m 0s | Loss: 3.681\n",
      "Time Elapsed: 207m 4s | Loss: 3.686\n",
      "Time Elapsed: 210m 9s | Loss: 3.69\n",
      "Time Elapsed: 213m 9s | Loss: 3.692\n",
      "Time Elapsed: 215m 5s | Loss: 3.695\n",
      "Time Elapsed: 217m 1s | Loss: 3.698\n",
      "Time Elapsed: 218m 58s | Loss: 3.701\n",
      "Time Elapsed: 221m 57s | Loss: 3.705\n",
      "Time Elapsed: 225m 1s | Loss: 3.708\n",
      "Time Elapsed: 228m 7s | Loss: 3.711\n",
      "Time Elapsed: 231m 11s | Loss: 3.713\n",
      "Epoch: 14 | Time Elapsed: 239m 7s | Loss: 3.712 | Train BLEU: 2.304 | Dev BLEU: 0.9924\n",
      "Time Elapsed: 242m 12s | Loss: 3.567\n",
      "Time Elapsed: 245m 18s | Loss: 3.57\n",
      "Time Elapsed: 248m 23s | Loss: 3.579\n",
      "Time Elapsed: 251m 27s | Loss: 3.608\n",
      "Time Elapsed: 254m 30s | Loss: 3.617\n",
      "Time Elapsed: 257m 36s | Loss: 3.62\n",
      "Time Elapsed: 260m 41s | Loss: 3.622\n",
      "Time Elapsed: 263m 47s | Loss: 3.626\n",
      "Time Elapsed: 266m 52s | Loss: 3.629\n",
      "Time Elapsed: 269m 57s | Loss: 3.632\n",
      "Time Elapsed: 273m 1s | Loss: 3.636\n",
      "Time Elapsed: 276m 6s | Loss: 3.639\n",
      "Time Elapsed: 279m 11s | Loss: 3.642\n",
      "Time Elapsed: 282m 16s | Loss: 3.644\n",
      "Time Elapsed: 284m 20s | Loss: 3.648\n",
      "Time Elapsed: 286m 16s | Loss: 3.652\n",
      "Time Elapsed: 288m 13s | Loss: 3.655\n",
      "Time Elapsed: 291m 0s | Loss: 3.658\n",
      "Epoch: 15 | Time Elapsed: 298m 52s | Loss: 3.656 | Train BLEU: 1.943 | Dev BLEU: 1.127\n",
      "Time Elapsed: 301m 17s | Loss: 3.501\n",
      "Time Elapsed: 303m 41s | Loss: 3.506\n",
      "Time Elapsed: 306m 5s | Loss: 3.518\n",
      "Time Elapsed: 308m 24s | Loss: 3.526\n",
      "Time Elapsed: 310m 48s | Loss: 3.533\n",
      "Time Elapsed: 314m 40s | Loss: 3.541\n",
      "Time Elapsed: 321m 2s | Loss: 3.545\n",
      "Time Elapsed: 327m 25s | Loss: 3.552\n",
      "Time Elapsed: 333m 48s | Loss: 3.556\n",
      "Time Elapsed: 340m 11s | Loss: 3.561\n",
      "Time Elapsed: 346m 34s | Loss: 3.566\n",
      "Time Elapsed: 352m 53s | Loss: 3.571\n",
      "Time Elapsed: 359m 16s | Loss: 3.575\n",
      "Time Elapsed: 365m 38s | Loss: 3.58\n",
      "Time Elapsed: 372m 2s | Loss: 3.584\n",
      "Time Elapsed: 378m 24s | Loss: 3.588\n",
      "Time Elapsed: 384m 47s | Loss: 3.591\n",
      "Time Elapsed: 390m 28s | Loss: 3.595\n",
      "Epoch: 16 | Time Elapsed: 410m 14s | Loss: 3.595 | Train BLEU: 3.619 | Dev BLEU: 1.991\n",
      "Time Elapsed: 413m 34s | Loss: 3.454\n",
      "Time Elapsed: 416m 56s | Loss: 3.463\n",
      "Time Elapsed: 420m 17s | Loss: 3.475\n",
      "Time Elapsed: 422m 30s | Loss: 3.481\n",
      "Time Elapsed: 425m 4s | Loss: 3.486\n",
      "Time Elapsed: 428m 19s | Loss: 3.495\n",
      "Time Elapsed: 431m 34s | Loss: 3.501\n"
     ]
    }
   ],
   "source": [
    "fit(train_loader, dev_loader, zh_encoder, zh_decoder, zh_encoder_optimizer, zh_decoder_optimizer, zh_criterion, BATCH_SIZE, 15, 300, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
