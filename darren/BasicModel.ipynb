{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from utils import asMinutes, timeSince, load_zipped_pickle, corpus_bleu, directories\n",
    "from langUtils import loadLangPairs, langDataset, langCollateFn, initHybridEmbeddings, tensorToList\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dictionaries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pkl.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sentence given numbers\n",
    "def ids2sentence(sentence, dictionary):\n",
    "    return ' '.join([dictionary[i] for i in sentence])\n",
    "#ids2sentence(en_train_num[0], id2word_en_dic)\n",
    "\n",
    "def add_symbol(id2word_dic, word2id_dic):\n",
    "    symbols = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        id2word_dic[i] = symbol\n",
    "        word2id_dic[symbol] = i\n",
    "    return id2word_dic, word2id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word_vi_dic = load_zipped_pickle(\"../embeddings/id2word_vi_dic.p\")\n",
    "# word2id_vi_dic = load_zipped_pickle(\"../embeddings/word2id_vi_dic.p\")\n",
    "\n",
    "# id2word_en_dic = load_zipped_pickle(\"../embeddings/id2word_en_dic.p\")\n",
    "# word2id_en_dic = load_zipped_pickle(\"../embeddings/word2id_en_dic.p\")\n",
    "\n",
    "# id2word_vi_dic, word2id_vi_dic = add_symbol(id2word_vi_dic, word2id_vi_dic)\n",
    "# id2word_en_dic, word2id_en_dic = add_symbol(id2word_en_dic, word2id_en_dic)\n",
    "\n",
    "# vi_train = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok.p\")\n",
    "# en_train = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok.p\") # Already Processed for symbols\n",
    "\n",
    "# vi_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_vi_tok_num.p\")\n",
    "# en_train_num = load_zipped_pickle(\"../data/vi-en-tokens/train_en_tok_num.p\") # Already Processed for symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi, en = loadLangPairs(\"vi\")\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = langDataset([(vi.train_num[i], en.train_num[i]) for i in range(len(vi.train_num)) if (len(vi.train[i]) < vi.max_length) & (len(en.train[i]) < en.max_length)])\n",
    "overfit_dataset = langDataset([(vi.train_num[i], en.train_num[i]) for i in range(2)])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)\n",
    "dev_dataset = langDataset([(vi.dev_num[i], en.dev_num[i]) for i in range(len(vi.dev_num)) if (len(vi.dev[i]) < vi.max_length) & (len(en.dev[i]) < en.max_length)])\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_SYMBOLS_ID = PAD_ID, UNK_ID, SOS_ID, EOS_ID = 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by input data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sort_by_length(data_input, target_data):\n",
    "#     input_size = [len(data) for data in data_input]\n",
    "#     size_index = np.argsort(input_size)\n",
    "#     return list(np.array(data_input)[size_index]), list(np.array(target_data)[size_index])\n",
    "\n",
    "# vi_train_num, en_train_num = sort_by_length(vi_train_num, en_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Data given batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(data, length):\n",
    "    for i, line in enumerate(data):\n",
    "        if len(line) < length:\n",
    "            for i in range(len(line), length):\n",
    "                line.append(0)\n",
    "        else:\n",
    "            data[i] = line[0:length]\n",
    "    return data\n",
    "\n",
    "# Return the batch data and target\n",
    "def get_batch(i, batch_size, train_data, train_target):\n",
    "    if i * batch_size > len(train_data):\n",
    "        raise Exception('Incorrect batch index')\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    batch_data = list(np.array(train_data)[start_idx:end_idx])\n",
    "    batch_target = list(np.array(train_target)[start_idx:end_idx])\n",
    "    batch_data = pad(batch_data, len(batch_data[batch_size - 1]))\n",
    "    max_target = max([len(data) for data in batch_data])\n",
    "    batch_target = pad(batch_target, max_target)\n",
    "    return batch_data, batch_target\n",
    "\n",
    "# get_batch(5, 64, vi_train_num, en_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # input_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size, \n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH FIRST\n",
    "\n",
    "    def forward(self, encoder_input, hidden_input):\n",
    "        # encoder_input: batch * 1 (for 1 word each time)\n",
    "        embedded_input = self.embedding(encoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        # hidden_input: batch * 1(layer) * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, batch_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        # output_size: input dictionary size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size,\n",
    "                          num_layers= num_layers, \n",
    "                          batch_first = True) # BATCH_FRIST\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1) # Use cross entropy loss outside\n",
    "\n",
    "    def forward(self, decoder_input, hidden_input):\n",
    "        # decoder_input: batch * 1\n",
    "        embedded_input = self.embedding(decoder_input)\n",
    "        # embedded_input: batch * 1 * emb_dim\n",
    "        embedded_input = F.relu(embedded_input)\n",
    "        # hidden_input: batch * hidden_size\n",
    "        output, hidden = self.gru(embedded_input, hidden_input)\n",
    "        output = self.out(output)\n",
    "        # output = self.softmax(output) # not using softmax\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, output, out_max, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size):\n",
    "    total_avg_loss = 0\n",
    "    loss = 0\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_len = inp.shape[1]\n",
    "    encoder_outputs = torch.zeros(input_len, batch_size, 1, HIDDEN_SIZE, device=device)\n",
    "    encoder_hiddens = torch.zeros(input_len, 1, batch_size, HIDDEN_SIZE, device=device)\n",
    "    # Encode\n",
    "    for ec_idx in range(input_len):\n",
    "        # input batch_size * 1\n",
    "        encoder_output, encoder_hidden = encoder(inp[:, ec_idx].unsqueeze(1), encoder_hidden)\n",
    "        encoder_outputs[ec_idx] = encoder_output\n",
    "        encoder_hiddens[ec_idx] = encoder_hidden\n",
    "\n",
    "    # Decode\n",
    "    decoder_input = torch.tensor([SOS_ID] * batch_size, device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Always use Teacher Forcing\n",
    "    for dc_idx in range(out_max):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input.unsqueeze(1), decoder_hidden)\n",
    "        decoder_output = decoder_output.squeeze(1).to(device) # get rid of the seq dimention\n",
    "        loss += criterion(decoder_output, output[:, dc_idx])\n",
    "        decoder_input = output[:, dc_idx]\n",
    "\n",
    "        ## Print Value\n",
    "#         sample_sentence.append(torch.argmax(decoder_output[0]).item())\n",
    "\n",
    "    loss.backward()\n",
    "    total_avg_loss += loss.item() / out_max\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    ## Print Value\n",
    "#     print(\"Predict: \", ids2sentence(sample_sentence, en.id2word))\n",
    "#     print(\"Actual: \", ids2sentence(output[0].cpu().numpy(), en.id2word))\n",
    "        \n",
    "    return total_avg_loss\n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleuEval(encoder, decoder, data_loader, batch_size):\n",
    "    with torch.no_grad():\n",
    "        true_outputs = []\n",
    "        decoder_outputs = []\n",
    "        for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(train_loader):\n",
    "            if i * batch_size >= 10000 or len(inp[0]) != batch_size:\n",
    "                continue\n",
    "            inp = inp.transpose(0,1).to(device)\n",
    "            output = output.transpose(0,1).to(device)\n",
    "            true_outputs.append([[str(tok.item()) for tok in out if tok != 0] for out in output])\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            input_len = inp.shape[1]\n",
    "            encoder_outputs = torch.zeros(input_len, batch_size, 1, HIDDEN_SIZE, device=device)\n",
    "            encoder_hiddens = torch.zeros(input_len, 1, batch_size, HIDDEN_SIZE, device=device)\n",
    "\n",
    "            # Encode\n",
    "            for ec_idx in range(input_len):\n",
    "                # input batch_size * 1\n",
    "                encoder_output, encoder_hidden = encoder(inp[:, ec_idx].unsqueeze(1), encoder_hidden)\n",
    "                encoder_outputs[ec_idx] = encoder_output\n",
    "                encoder_hiddens[ec_idx] = encoder_hidden\n",
    "\n",
    "            # Decode\n",
    "            decoder_input = torch.tensor([SOS_ID] * batch_size, device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            # Greedy\n",
    "            for dc_idx in range(out_max):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input.unsqueeze(1), decoder_hidden)\n",
    "                decoder_output = decoder_output.squeeze(1).to(device) # get rid of the seq dimention\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = torch.LongTensor([topi[i][0] for i in range(inp.size(0))]).to(device)\n",
    "                ## Print Value\n",
    "                decoder_outputs.append(list(decoder_input.cpu().numpy()))\n",
    "            ## Print Value\n",
    "        predict = []\n",
    "        for seq in np.array(decoder_outputs).T.astype(str):\n",
    "            seq_toks = []\n",
    "            for tok in seq:\n",
    "                seq_toks.append(tok)\n",
    "                if tok == '3':\n",
    "                    break\n",
    "            predict.append(seq_toks)\n",
    "        print('Sample True: ', ' '.join([en.id2word[int(i)] for i in true_outputs[0][0]]))\n",
    "        print('Sample Predicted: ', ' '.join([en.id2word[int(i)] for i in predict[0]]))\n",
    "        bleu_score = corpus_bleu(predict, true_outputs, 4)\n",
    "        return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_loader, dev_loader, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, epochs, print_every):\n",
    "    start = time.time()\n",
    "    print('Initializing Model Training + Eval...')\n",
    "    losses = []\n",
    "    train_scores = []\n",
    "    dev_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(train_loader):\n",
    "            if (len(inp[0]) != batch_size):\n",
    "                continue\n",
    "            inp.transpose_(0,1)\n",
    "            output.transpose_(0,1)\n",
    "            inp = inp.to(device)\n",
    "            output = output.to(device)\n",
    "            loss += train(inp, output, out_max, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size)\n",
    "            if i % print_every == 0 and i > 0:\n",
    "                losses.append(loss/i)\n",
    "                print(\"Time Elapsed: {} | Loss: {:.4}\".format(asMinutes(time.time() - start),\n",
    "                                                                                loss/i))\n",
    "        train_score = bleuEval(encoder, decoder, train_loader, batch_size)\n",
    "        dev_score = bleuEval(encoder, decoder, dev_loader, batch_size)\n",
    "        train_scores.append(train_score)\n",
    "        dev_scores.append(dev_score)\n",
    "        print(\"Epoch: {} | Time Elapsed: {} | Loss: {:.4} | Train BLEU: {:.4} | Dev BLEU: {:.4}\".format(epoch + 1, \n",
    "                                                                                                        asMinutes(time.time() - start),\n",
    "                                                                                                        loss/len(train_loader), \n",
    "                                                                                                        train_score, \n",
    "                                                                                                        dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_size_vi = len(id2word_vi_dic.keys())\n",
    "# dic_size_en = len(id2word_en_dic.keys())\n",
    "HIDDEN_SIZE = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "## Add ignore index\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "encoder = EncoderRNN(input_size = vi.n_words, hidden_size = HIDDEN_SIZE, num_layers = 1, batch_size = BATCH_SIZE).to(device)\n",
    "decoder = DecoderRNN(hidden_size = HIDDEN_SIZE, output_size = en.n_words, num_layers = 1, batch_size = BATCH_SIZE).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model Training + Eval...\n",
      "Time Elapsed: 4m 13s | Loss: 5.741\n",
      "Time Elapsed: 8m 16s | Loss: 5.55\n",
      "Time Elapsed: 12m 10s | Loss: 5.456\n",
      "Time Elapsed: 16m 24s | Loss: 5.368\n",
      "Time Elapsed: 20m 26s | Loss: 5.299\n",
      "Time Elapsed: 24m 18s | Loss: 5.24\n",
      "Time Elapsed: 28m 30s | Loss: 5.197\n",
      "Time Elapsed: 32m 36s | Loss: 5.156\n",
      "Time Elapsed: 36m 25s | Loss: 5.124\n",
      "Time Elapsed: 40m 37s | Loss: 5.094\n",
      "Time Elapsed: 44m 45s | Loss: 5.067\n",
      "Epoch: 1 | Time Elapsed: 46m 32s | Loss: 5.054 | Train BLEU: 1.563 | Dev BLEU: 1.069\n",
      "Time Elapsed: 50m 37s | Loss: 4.608\n",
      "Time Elapsed: 54m 48s | Loss: 4.597\n",
      "Time Elapsed: 58m 31s | Loss: 4.575\n",
      "Time Elapsed: 62m 43s | Loss: 4.55\n",
      "Time Elapsed: 66m 54s | Loss: 4.54\n",
      "Time Elapsed: 70m 39s | Loss: 4.529\n",
      "Time Elapsed: 74m 51s | Loss: 4.518\n",
      "Time Elapsed: 79m 3s | Loss: 4.51\n",
      "Time Elapsed: 82m 48s | Loss: 4.501\n",
      "Time Elapsed: 86m 58s | Loss: 4.493\n",
      "Time Elapsed: 91m 10s | Loss: 4.486\n",
      "Epoch: 2 | Time Elapsed: 93m 10s | Loss: 4.481 | Train BLEU: 2.315 | Dev BLEU: 2.702\n",
      "Time Elapsed: 97m 1s | Loss: 4.145\n",
      "Time Elapsed: 101m 14s | Loss: 4.15\n",
      "Time Elapsed: 105m 21s | Loss: 4.16\n",
      "Time Elapsed: 109m 8s | Loss: 4.163\n",
      "Time Elapsed: 113m 21s | Loss: 4.168\n",
      "Time Elapsed: 117m 30s | Loss: 4.18\n",
      "Time Elapsed: 121m 14s | Loss: 4.189\n",
      "Time Elapsed: 125m 27s | Loss: 4.194\n",
      "Time Elapsed: 129m 40s | Loss: 4.198\n",
      "Time Elapsed: 133m 25s | Loss: 4.2\n",
      "Time Elapsed: 137m 38s | Loss: 4.204\n",
      "Epoch: 3 | Time Elapsed: 139m 49s | Loss: 4.203 | Train BLEU: 2.007 | Dev BLEU: 6.053\n",
      "Time Elapsed: 143m 35s | Loss: 3.935\n",
      "Time Elapsed: 147m 49s | Loss: 3.957\n",
      "Time Elapsed: 152m 0s | Loss: 3.968\n",
      "Time Elapsed: 155m 44s | Loss: 3.975\n",
      "Time Elapsed: 159m 57s | Loss: 3.984\n",
      "Time Elapsed: 164m 8s | Loss: 3.991\n",
      "Time Elapsed: 167m 55s | Loss: 4.001\n",
      "Time Elapsed: 172m 7s | Loss: 4.008\n",
      "Time Elapsed: 176m 20s | Loss: 4.015\n",
      "Time Elapsed: 180m 10s | Loss: 4.022\n",
      "Time Elapsed: 184m 18s | Loss: 4.028\n",
      "Epoch: 4 | Time Elapsed: 186m 23s | Loss: 4.029 | Train BLEU: 1.628 | Dev BLEU: 2.186\n",
      "Time Elapsed: 190m 30s | Loss: 3.786\n",
      "Time Elapsed: 194m 21s | Loss: 3.806\n",
      "Time Elapsed: 198m 35s | Loss: 3.824\n",
      "Time Elapsed: 202m 44s | Loss: 3.839\n",
      "Time Elapsed: 206m 31s | Loss: 3.855\n",
      "Time Elapsed: 210m 43s | Loss: 3.868\n",
      "Time Elapsed: 214m 53s | Loss: 3.879\n",
      "Time Elapsed: 218m 39s | Loss: 3.889\n",
      "Time Elapsed: 222m 52s | Loss: 3.896\n",
      "Time Elapsed: 226m 55s | Loss: 3.905\n",
      "Time Elapsed: 230m 49s | Loss: 3.912\n",
      "Epoch: 5 | Time Elapsed: 232m 51s | Loss: 3.913 | Train BLEU: 4.11 | Dev BLEU: 3.036\n",
      "Time Elapsed: 237m 4s | Loss: 3.715\n",
      "Time Elapsed: 240m 48s | Loss: 3.734\n",
      "Time Elapsed: 244m 59s | Loss: 3.747\n",
      "Time Elapsed: 249m 11s | Loss: 3.761\n",
      "Time Elapsed: 252m 57s | Loss: 3.777\n",
      "Time Elapsed: 257m 6s | Loss: 3.788\n",
      "Time Elapsed: 261m 20s | Loss: 3.801\n",
      "Time Elapsed: 265m 13s | Loss: 3.812\n",
      "Time Elapsed: 269m 16s | Loss: 3.825\n",
      "Time Elapsed: 273m 29s | Loss: 3.836\n",
      "Time Elapsed: 277m 23s | Loss: 3.846\n",
      "Epoch: 6 | Time Elapsed: 279m 20s | Loss: 3.847 | Train BLEU: 4.179 | Dev BLEU: 3.274\n",
      "Time Elapsed: 283m 32s | Loss: 3.66\n",
      "Time Elapsed: 287m 43s | Loss: 3.681\n",
      "Time Elapsed: 291m 29s | Loss: 3.695\n",
      "Time Elapsed: 295m 41s | Loss: 3.715\n",
      "Time Elapsed: 299m 54s | Loss: 3.729\n",
      "Time Elapsed: 303m 36s | Loss: 3.74\n",
      "Time Elapsed: 307m 49s | Loss: 3.753\n",
      "Time Elapsed: 311m 56s | Loss: 3.762\n",
      "Time Elapsed: 315m 41s | Loss: 3.772\n",
      "Time Elapsed: 319m 51s | Loss: 3.782\n",
      "Time Elapsed: 323m 58s | Loss: 3.791\n",
      "Epoch: 7 | Time Elapsed: 325m 47s | Loss: 3.794 | Train BLEU: 2.771 | Dev BLEU: 5.678\n",
      "Time Elapsed: 329m 50s | Loss: 3.587\n",
      "Time Elapsed: 334m 0s | Loss: 3.618\n",
      "Time Elapsed: 337m 56s | Loss: 3.637\n",
      "Time Elapsed: 341m 53s | Loss: 3.665\n",
      "Time Elapsed: 346m 2s | Loss: 3.687\n",
      "Time Elapsed: 349m 59s | Loss: 3.711\n",
      "Time Elapsed: 353m 54s | Loss: 3.725\n",
      "Time Elapsed: 358m 5s | Loss: 3.742\n",
      "Time Elapsed: 362m 4s | Loss: 3.753\n",
      "Time Elapsed: 365m 57s | Loss: 3.764\n",
      "Time Elapsed: 370m 8s | Loss: 3.773\n",
      "Epoch: 8 | Time Elapsed: 372m 13s | Loss: 3.775 | Train BLEU: 2.516 | Dev BLEU: 5.869\n",
      "Time Elapsed: 375m 59s | Loss: 3.588\n",
      "Time Elapsed: 380m 10s | Loss: 3.608\n",
      "Time Elapsed: 384m 21s | Loss: 3.627\n",
      "Time Elapsed: 388m 4s | Loss: 3.645\n",
      "Time Elapsed: 392m 13s | Loss: 3.66\n",
      "Time Elapsed: 396m 23s | Loss: 3.678\n",
      "Time Elapsed: 400m 4s | Loss: 3.692\n",
      "Time Elapsed: 404m 13s | Loss: 3.704\n",
      "Time Elapsed: 408m 24s | Loss: 3.716\n",
      "Time Elapsed: 412m 6s | Loss: 3.729\n",
      "Time Elapsed: 416m 16s | Loss: 3.74\n",
      "Epoch: 9 | Time Elapsed: 418m 15s | Loss: 3.742 | Train BLEU: 2.775 | Dev BLEU: 5.751\n",
      "Time Elapsed: 422m 18s | Loss: 3.598\n",
      "Time Elapsed: 426m 7s | Loss: 3.616\n",
      "Time Elapsed: 430m 16s | Loss: 3.63\n",
      "Time Elapsed: 434m 22s | Loss: 3.644\n",
      "Time Elapsed: 438m 10s | Loss: 3.659\n",
      "Time Elapsed: 442m 20s | Loss: 3.669\n",
      "Time Elapsed: 446m 27s | Loss: 3.678\n",
      "Time Elapsed: 450m 12s | Loss: 3.687\n",
      "Time Elapsed: 454m 20s | Loss: 3.697\n",
      "Time Elapsed: 458m 31s | Loss: 3.707\n",
      "Time Elapsed: 462m 15s | Loss: 3.716\n",
      "Epoch: 10 | Time Elapsed: 464m 16s | Loss: 3.718 | Train BLEU: 5.838 | Dev BLEU: 3.0\n"
     ]
    }
   ],
   "source": [
    "fit(train_loader, dev_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, BATCH_SIZE, 10, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample True:  <sos> a few days after arriving , i met this wonderful , old conductor who started casting me in all of these roles . <eos>\n",
      "Sample Predicted:  <sos> i want to be able to do the truth , i want to be able to do the truth . <eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.984592578474465"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleuEval(encoder, decoder, train_loader, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-52846243a1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/encoder.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/decoder.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "pkl.dump(encoder, open(\"./model/encoder.p\", \"wb\"))\n",
    "pickle.dump(decoder, open(\"./model/decoder.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.gru.batch_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m(143)\u001b[0;36mcheck_hidden_size\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    141 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 143 \u001b[0;31m                \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    145 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'encoder' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-31-f7ca4d53521a>\u001b[0m(15)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m        \u001b[0;31m# input batch_size * 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mec_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m        \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mec_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mec_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  enoder_outputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'enoder_outputs' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  encoder_outputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]],\n",
      "\n",
      "         [[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]],\n",
      "\n",
      "         [[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]],\n",
      "\n",
      "         [[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]],\n",
      "\n",
      "         [[ 0.0170,  0.1717,  0.3893,  ...,  0.0381, -0.1810, -0.2559]]],\n",
      "\n",
      "\n",
      "        [[[-0.0219, -0.0105, -0.2507,  ...,  0.1992, -0.4429, -0.4246]],\n",
      "\n",
      "         [[-0.0108,  0.4253,  0.3838,  ..., -0.2613,  0.1234, -0.1874]],\n",
      "\n",
      "         [[-0.2046, -0.4536,  0.5676,  ...,  0.0421,  0.3484, -0.3940]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036, -0.4598,  0.2498,  ..., -0.1157,  0.1377,  0.2163]],\n",
      "\n",
      "         [[-0.0036, -0.4598,  0.2498,  ..., -0.1157,  0.1377,  0.2163]],\n",
      "\n",
      "         [[-0.0856,  0.0131,  0.2655,  ...,  0.2046, -0.2525, -0.0867]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4918, -0.1363,  0.1370,  ...,  0.0146, -0.2607, -0.5579]],\n",
      "\n",
      "         [[-0.1242,  0.3349,  0.5718,  ..., -0.3327,  0.2256, -0.0852]],\n",
      "\n",
      "         [[-0.3152, -0.5568,  0.6375,  ...,  0.0403,  0.5346, -0.4440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0275,  0.3268, -0.1821,  ..., -0.0095,  0.1823,  0.4863]],\n",
      "\n",
      "         [[ 0.0017, -0.0015,  0.0989,  ..., -0.2592,  0.0363,  0.3519]],\n",
      "\n",
      "         [[ 0.1362,  0.0032,  0.2977,  ..., -0.0740, -0.0210, -0.0719]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1357,  0.1549,  0.2249,  ...,  0.0175,  0.4587,  0.1154]],\n",
      "\n",
      "         [[-0.1083, -0.2688,  0.4672,  ...,  0.2151, -0.3381,  0.1786]],\n",
      "\n",
      "         [[ 0.2141, -0.3156,  0.1468,  ...,  0.4485, -0.3331, -0.3143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0820, -0.9278,  0.6974,  ...,  0.4278,  0.5836, -0.7664]],\n",
      "\n",
      "         [[-0.0804, -0.9272,  0.6960,  ...,  0.4278,  0.5823, -0.7665]],\n",
      "\n",
      "         [[-0.0783, -0.9280,  0.6984,  ...,  0.4253,  0.5912, -0.7671]]],\n",
      "\n",
      "\n",
      "        [[[-0.3314,  0.3519,  0.2042,  ..., -0.6216,  0.3659,  0.0270]],\n",
      "\n",
      "         [[-0.5117, -0.0432, -0.2642,  ...,  0.3886, -0.2846, -0.2133]],\n",
      "\n",
      "         [[ 0.2323, -0.4987, -0.0415,  ..., -0.0950, -0.3297, -0.1025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0801, -0.9281,  0.6986,  ...,  0.4258,  0.5901, -0.7666]],\n",
      "\n",
      "         [[-0.0789, -0.9276,  0.6976,  ...,  0.4258,  0.5892, -0.7667]],\n",
      "\n",
      "         [[-0.0773, -0.9281,  0.6992,  ...,  0.4241,  0.5948, -0.7671]]],\n",
      "\n",
      "\n",
      "        [[[-0.1126, -0.0602,  0.0442,  ..., -0.0315,  0.2195, -0.5180]],\n",
      "\n",
      "         [[-0.1126,  0.0772, -0.5050,  ..., -0.0286, -0.3123,  0.3051]],\n",
      "\n",
      "         [[ 0.0513, -0.1630, -0.1074,  ...,  0.0284,  0.2293, -0.2188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0788, -0.9282,  0.6993,  ...,  0.4244,  0.5944, -0.7668]],\n",
      "\n",
      "         [[-0.0778, -0.9278,  0.6987,  ...,  0.4244,  0.5938, -0.7668]],\n",
      "\n",
      "         [[-0.0766, -0.9281,  0.6997,  ...,  0.4233,  0.5973, -0.7671]]]],\n",
      "       device='cuda:0', grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(encoder_outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  encoder_outputs[23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: index 23 is out of bounds for dimension 0 with size 23\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict:  ['<sos>', '<sos>', '<sos>', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  8.810749053955078\n",
      "Predict:  ['<sos>', '<sos>', 'the', 'the', 'the', 'two', 'the', 'the', 'the', 'freaky']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  4.840537643432617\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'the', 'the', 'the', 'freaky']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  1.9151222229003906\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.9088132858276368\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.5086045742034913\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.3032816410064697\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.18692054748535156\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.12194809913635254\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.08495545387268066\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.06054344177246094\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.043548297882080075\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.03167123794555664\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.023690128326416017\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Loss:  0.017924118041992187\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f6d188e37f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_vi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_en_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-a1868babeca0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_data, target_data, encoder, decoder, encoder_opt, decoder_opt, criterion, batch_size, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3b1f9816ee80>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtotal_avg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, BATCH_SIZE, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  8.852307891845703\n",
      "Predict:  ['<sos>', '<sos>', 'the', 'just', 'these', 'the', 'notes', 'the', 'the', 'the']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  4.9451759338378904\n",
      "Predict:  ['<sos>', '<sos>', 'coming', 'just', 'these', 'notes', 'notes', 'the', 'the', 'the']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  1.9719776153564452\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'notes', 'the', 'the', 'freaky']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.9234449386596679\n",
      "Predict:  ['<sos>', '<sos>', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'freaky']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.5161348819732666\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.3111863613128662\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.19171581268310547\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.1251605987548828\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.08669190406799317\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.06085610389709473\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.043444252014160155\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0317835807800293\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.02393932342529297\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.018381881713867187\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.014472675323486329\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.011426544189453125\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.009125995635986327\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0074138641357421875\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.006087779998779297\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.005056858062744141\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.004248332977294922\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0036081314086914063\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0030983924865722657\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0026922225952148438\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0023674964904785156\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.002105426788330078\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.001891326904296875\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0017138481140136718\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0015657424926757812\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0014398574829101562\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.00133209228515625\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0012396812438964845\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0011590957641601563\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.001088714599609375\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0010272979736328125\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0009730339050292968\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0009249687194824219\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0008824348449707031\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.000844573974609375\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0008105278015136719\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0007798194885253907\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.00075225830078125\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0007273674011230469\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0007046699523925781\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0006839752197265625\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0006653785705566407\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0006479263305664062\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0006319999694824219\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.000617218017578125\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.000603485107421875\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005910873413085937\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005793571472167969\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005681991577148437\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005581855773925781\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.000548553466796875\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005395889282226562\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005313873291015625\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005230903625488281\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n",
      "Training Loss:  0.0005156517028808594\n",
      "Predict:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Actual:  ['<sos>', 'it', 's', 'just', 'these', 'two', 'notes', 'in', 'the', 'middle']\n",
      "Training Complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-78ec3519bd0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverfit_vi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit_en_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-256264019c3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLP/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(1000):\n",
    "#     train(overfit_vi_train, overfit_en_train, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(train_input, train_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size):\n",
    "#     # Batch\n",
    "#     total_avg_loss = 0\n",
    "#     for i in range(len(train_input) // batch_size):\n",
    "#         loss = 0\n",
    "#         encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "#         batch = get_batch(i, batch_size, train_input, train_target)\n",
    "#         # size batch_size * seq_length\n",
    "#         batch_input = torch.tensor(batch[0], device=device)\n",
    "#         batch_target = torch.tensor(batch[1], device=device)\n",
    "#         input_length = batch_input.shape[1] ## should be seq length\n",
    "#         target_length = batch_target.shape[1]\n",
    "#         print(input_length, target_length)\n",
    "\n",
    "#         encoder_optimizer.zero_grad()\n",
    "#         decoder_optimizer.zero_grad()\n",
    "        \n",
    "#         encoder_outputs = torch.zeros(input_length, batch_size, 1, 256, device=device)\n",
    "#         encoder_hiddens = torch.zeros(input_length, 1, batch_size, 256, device=device)\n",
    "        \n",
    "#         # Encode\n",
    "#         for ec_idx in range(input_length):\n",
    "#             # input batch_size * 1\n",
    "#             encoder_output, encoder_hidden = encoder(batch_input[:, ec_idx].unsqueeze(1), encoder_hidden)\n",
    "#             encoder_outputs[ec_idx] = encoder_output\n",
    "#             encoder_hiddens[ec_idx] = encoder_hidden\n",
    "        \n",
    "#         # Decode\n",
    "#         decoder_input = torch.tensor([2] * batch_size, device=device) # SOS token 2\n",
    "#         decoder_hidden = encoder_hidden\n",
    "        \n",
    "#         ## Print Value\n",
    "#         sample_sentence = []\n",
    "        \n",
    "#         # Always use Teacher Forcing\n",
    "#         for dc_idx in range(target_length):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input.unsqueeze(1), decoder_hidden)\n",
    "#             decoder_output = decoder_output.squeeze(1).to(device) # get rid of the seq dimention\n",
    "#             loss += criterion(decoder_output, batch_target[:, dc_idx])\n",
    "#             decoder_input = batch_target[:, dc_idx]\n",
    "            \n",
    "#             ## Print Value\n",
    "#             sample_sentence.append(torch.argmax(decoder_output[0]).item())\n",
    "            \n",
    "#         loss.backward()\n",
    "#         total_avg_loss += loss.item() / target_length\n",
    "        \n",
    "#         encoder_optimizer.step()\n",
    "#         decoder_optimizer.step()\n",
    "        \n",
    "# #         print('Training Loss: ', loss.item() / target_length)\n",
    "        \n",
    "#         ## Print Value\n",
    "#         print(\"Predict: \", ids2sentence(sample_sentence, id2word_en_dic))\n",
    "#         print(\"Actual: \", ids2sentence(batch_target[0].cpu().numpy(), id2word_en_dic))\n",
    "        \n",
    "#     return total_avg_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
