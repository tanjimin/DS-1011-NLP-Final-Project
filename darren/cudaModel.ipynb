{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils import asMinutes, timeSince, load_zipped_pickle, corpus_bleu, directories\n",
    "from langUtils import loadLangPairs, langDataset, langCollateFn, initHybridEmbeddings, tensorToList\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedList(list):\n",
    "    def insort(self, x):\n",
    "        bisect.insort(self, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir, em_dir = directories()\n",
    "\n",
    "SPECIAL_SYMBOLS_ID = PAD_ID, UNK_ID, SOS_ID, EOS_ID = 0, 1, 2, 3\n",
    "NUM_SPECIAL = len(SPECIAL_SYMBOLS_ID)\n",
    "\n",
    "vi, en = loadLangPairs(\"vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = langDataset([(vi.train_num[i], en.train_num[i]) for i in range(len(vi.train_num)) if (len(vi.train[i]) < vi.max_length) & (len(en.train[i]) < en.max_length)])\n",
    "overfit_dataset = langDataset([(vi.train_num[i], en.train_num[i]) for i in range(2)])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=overfit_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=False)\n",
    "dev_dataset = langDataset([(vi.dev_num[i], en.dev_num[i]) for i in range(len(vi.dev_num)) if (len(vi.dev[i]) < vi.max_length) & (len(en.dev[i]) < en.max_length)])\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=langCollateFn,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, params, raw_emb, learn_ids):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = params['hidden_size']\n",
    "        self.num_layers = params['num_layers']\n",
    "        \n",
    "        self.embedding = initHybridEmbeddings(raw_emb, learn_ids)\n",
    "        self.gru = nn.GRU(self.embedding.embedding_dim, params['hidden_size'], self.num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, inp, inp_lens, hidden=None):\n",
    "        embedded = self.embedding(inp)\n",
    "        packed = pack_padded_sequence(embedded, inp_lens)\n",
    "        \n",
    "        output, self.hidden = self.gru(packed, hidden)\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
    "        return output, self.hidden\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, params, raw_emb, learn_ids):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = params['hidden_size']\n",
    "        self.num_layers = params['num_layers']\n",
    "        self.output_size = params['output_size']\n",
    "\n",
    "        self.embedding = initHybridEmbeddings(raw_emb, learn_ids)\n",
    "        self.gru = nn.GRU(self.embedding.embedding_dim, params['hidden_size'], self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inp, hidden, encoder_output=None):\n",
    "        embedded = self.embedding(inp)\n",
    "        output = F.relu(embedded)\n",
    "        \n",
    "        output, self.hidden = self.gru(output, hidden)\n",
    "        orig = output\n",
    "        output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
    "        output = torch.exp(self.softmax(self.out(output))).squeeze(0)\n",
    "        return output, hidden, None\n",
    "\n",
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1).to(device)))\n",
    "    loss = crossEntropy.masked_select(mask.to(device)).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, encoder, decoder, encoder_optim, decoder_optim, beam_size):\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.encoder_optim = encoder_optim\n",
    "        self.decoder_optim = decoder_optim\n",
    "        \n",
    "        self.beam_size = beam_size\n",
    "        \n",
    "    def fit(self, train_data, dev_data, teacher_forcing_ratio, n_epoch, print_every, n_grams):\n",
    "        start = time.time()\n",
    "        \n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.n_epoch = n_epoch\n",
    "        \n",
    "        \n",
    "        print(\"Initializing...\")\n",
    "        start_epoch = 1\n",
    "        print_loss_total = 0 \n",
    "        plot_loss_total = 0\n",
    "        plot_losses = []\n",
    "        plot_train_scores = []\n",
    "        plot_dev_scores = []\n",
    "        \n",
    "        for epoch in range(start_epoch, n_epoch):\n",
    "            for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(train_loader):\n",
    "                loss = self.trainEpoch(inp, inp_lens, output, out_mask, out_max)\n",
    "                print_loss_total += loss\n",
    "                plot_loss_total += loss\n",
    "\n",
    "                if epoch  % print_every == 0:\n",
    "                    plot_loss_avg = plot_loss_total / print_every\n",
    "                    plot_losses.append(plot_loss_avg)\n",
    "                    plot_loss_total = 0       \n",
    "\n",
    "                    print_loss_avg = print_loss_total / print_every\n",
    "                    print_loss_total = 0\n",
    "                    print(\"{} ({} {}) Iter: {}/{} | Loss:{:.4}\".format(timeSince(start, epoch/n_epoch), \n",
    "                                                                                            epoch, \n",
    "                                                                                            epoch/n_epoch*100, \n",
    "                                                                                            i,\n",
    "                                                                                            len(train_loader),\n",
    "                                                                                            print_loss_avg))    \n",
    "            \n",
    "        train_score = self.bleuScore(train_loader, n_grams)\n",
    "        dev_score = self.bleuScore(dev_loader, n_grams)\n",
    "        plot_train_scores.append(train_score)\n",
    "        plot_dev_scores.append(dev_score)\n",
    "        print(\"EPOCH : {} | Train Score: {} | Dev Score: {}\".format(epoch, train_score, dev_score))\n",
    "        self.plot_losses = plot_losses\n",
    "        self.plot_train_scores = plot_train_scores\n",
    "        self.plot_dev_scores = plot_dev_scores\n",
    "        return \"Training Complete!\"            \n",
    "            \n",
    "    def trainEpoch(self, inp, inp_lens, output, out_mask, out_max):\n",
    "        self.encoder_optim.zero_grad()\n",
    "        self.decoder_optim.zero_grad()\n",
    "\n",
    "        loss, print_losses, n_totals = 0, [], 0\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder(inp, inp_lens)\n",
    "        \n",
    "        decoder_input = torch.LongTensor([[SOS_ID for _ in range(inp.size(1))]]).to(device)\n",
    "        decoder_hidden = encoder_hidden[:,-1:,:].contiguous()\n",
    "\n",
    "        if random.random() < self.teacher_forcing_ratio:\n",
    "            for t in range(out_max):\n",
    "                decoder_output, decoder_hidden, _ = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                decoder_input = output[t].view(1, -1)\n",
    "                \n",
    "                mask_loss, nTotal = maskNLLLoss(decoder_output, output[t], out_mask[t])\n",
    "                loss += mask_loss\n",
    "                print_losses.append(mask_loss.item() * nTotal)\n",
    "                n_totals += nTotal\n",
    "        else:\n",
    "            for t in range(out_max):\n",
    "                decoder_output, decoder_hidden, _ = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = torch.LongTensor([[topi[i][0] for i in range(inp.size(1))]]).to(device).detach()\n",
    "                \n",
    "                mask_loss, nTotal = maskNLLLoss(decoder_output, output[t], out_mask[t])\n",
    "                loss += mask_loss\n",
    "                print_losses.append(mask_loss.item() * nTotal)\n",
    "                n_totals += nTotal\n",
    "                \n",
    "        loss.backward()\n",
    "\n",
    "        self.encoder_optim.step()\n",
    "        self.decoder_optim.step()\n",
    "\n",
    "        return sum(print_losses) / n_totals\n",
    "    \n",
    "    def bleuScore(self, data_loader, n_grams):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            true_outputs = []\n",
    "            decoder_outputs = []\n",
    "\n",
    "            for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(data_loader):\n",
    "                if i * BATCH_SIZE >= 10000:\n",
    "                    break\n",
    "                if i > 0:\n",
    "                    break\n",
    "                print(' '.join([vi.id2word[int(i)] for i in inp[:,0]]))\n",
    "                print(' '.join([en.id2word[int(i)] for i in output[:,0]]))\n",
    "                true_outputs += tensorToList(output)\n",
    "\n",
    "                encoder_output, encoder_hidden = self.encoder(inp, inp_lens)\n",
    "\n",
    "                decoder_input = torch.LongTensor([[SOS_ID for _ in range(inp.size(1))]]) # appends <SOS> to beginning of decoded text\n",
    "                decoder_hidden = encoder_hidden[:,-1:,:].contiguous()\n",
    "\n",
    "                # BEAM SEARCH BELOW (size self.beam_size)\n",
    "                # candidates are stored as : (curr_scores, curr_sequences, decoder_hidden, decoder_input)\n",
    "                beam_size = 1\n",
    "                candidates = [([0 for _ in range(inp.size(1))], [[str(SOS_ID)] for _ in range(inp.size(1))], decoder_hidden, decoder_input) for _ in range(beam_size)]\n",
    "                for t in range(out_max):\n",
    "                    next_candidates = []\n",
    "                    next_candidate_scores = [SortedList() for _ in range(inp.size(1))] # list of sorted lists of candidate scores for each sentence\n",
    "                    next_candidate_inputs = [[] for _ in range(inp.size(1))] # dict from total curr score to next candidate token for each sentence\n",
    "                    next_candidate_seqs = [[] for _ in range(inp.size(1))] # dict from total curr score to next candidate sequence\n",
    "                    for curr_scores, curr_seqs, decoder_hidden, decoder_input in candidates:\n",
    "                        # generate output + next hidden state given input and current hidden state of the candidate\n",
    "                        decoder_output, decoder_hidden, _ = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                        topv, topi = decoder_output.topk(beam_size)\n",
    "                        for k in range(beam_size): \n",
    "                            # calculate for each sentence the next `beam_size` best possible next tokens\n",
    "                            for i in range(len(topi)):\n",
    "                                if len(topi[i]) != beam_size:\n",
    "                                    print('uhh', i, len(topi[i]))\n",
    "                            decoder_input = torch.LongTensor([[topi[i][k] for i in range(inp.size(1))]]).to(device)\n",
    "                            for i in range(inp.size(1)):\n",
    "                                # for sentence `i`, add `topi[i][k]` as a candidate if the new score for the seq is better than the other candidates\n",
    "                                if (curr_seqs[i][-1] == EOS_ID): #don't do anything with current sequence if already is EOS\n",
    "                                    continue \n",
    "                                curr_score = curr_scores[i] + topv[i][k].item()\n",
    "                                if (len(next_candidate_scores[i]) < beam_size or curr_score < next_candidate_scores[i][beam_size - 1]) and curr_score not in next_candidate_scores[i]:\n",
    "                                    if len(next_candidate_scores[i]) == beam_size:\n",
    "                                        next_candidate_inputs[i] = [candidate_input for candidate_input in next_candidate_inputs[i] if candidate_input[0] != next_candidate_scores[i][beam_size - 1]] # delete candidate associated with score\n",
    "                                        next_candidate_seqs[i] = [candidate_seq for candidate_seq in next_candidate_seqs[i] if candidate_seq[0] != next_candidate_scores[i][beam_size - 1]] # delete candidate associated with score\n",
    "                                        del next_candidate_scores[i][beam_size - 1] # delete associated score\n",
    "                                    next_candidate_scores[i].insort(curr_score) # insert new score in sorted order to scores lists for the i'th sentence\n",
    "                                    next_candidate_inputs[i].append((curr_score, topi[i][k].item())) # insert new token value for score key for the i'th sentence\n",
    "                                    next_candidate_seqs[i].append((curr_score, curr_seqs[i] + [str(topi[i][k].item())]))\n",
    "                    next_candidate_scores = [[score for score in next_candidate_scores[i]] for i in range(inp.size(1))]\n",
    "                    next_candidate_seqs = [[candidate_seq[1] for candidate_seq in sorted(next_candidate_seqs[i])] for i in range(inp.size(1))]\n",
    "                    next_candidate_inputs = [[candidate_input[1] for candidate_input in sorted(next_candidate_inputs[i])] for i in range(inp.size(1))]\n",
    "    #                 now that each best 3 sequences for each sentence is selected, create new candidates.\n",
    "                    for k in range(min(len(next_candidate_inputs[0]), len(next_candidate_scores[0]), len(next_candidate_seqs[0]))):\n",
    "                        decoder_input = torch.LongTensor([[next_candidate_inputs[i][k] for i in range(inp.size(1))]])\n",
    "                        next_scores = [next_candidate_scores[i][k] for i in range(inp.size(1))]\n",
    "                        next_seqs = [next_candidate_seqs[i][k] for i in range(inp.size(1))]\n",
    "                        next_candidates.append((next_scores, next_seqs, decoder_hidden, decoder_input))                            \n",
    "                    candidates = next_candidates\n",
    "                pred_outputs = [pred_out + [str(EOS_ID)] for pred_out in candidates[0][1]]\n",
    "                decoder_outputs += pred_outputs\n",
    "                print(' '.join([en.id2word[int(i)] for i in pred_outputs[0]])) \n",
    "                print(candidates[0][0])\n",
    "\n",
    "        return corpus_bleu(decoder_outputs, true_outputs, n_grams)\n",
    "\n",
    "    def showLoss(self):\n",
    "        plt.figure()\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        fig_plt = sns.lineplot(x=np.arange(0, self.n_epoch, int(self.n_epoch/len(self.plot_losses))), y=self.plot_losses)\n",
    "        fig_plt.set_title(\"Loss Over Time\")\n",
    "        fig_plt.set_ylabel(\"Loss\")\n",
    "        fig_plt.set_xlabel(\"Epochs\")\n",
    "        return fig_plt.get_figure()\n",
    "    \n",
    "    def showScore(self):\n",
    "        df = pd.concat([pd.DataFrame({'X':np.arange(0, self.n_epoch, int(self.n_epoch/len(self.plot_losses))), 'Y':self.plot_train_scores, 'Score':'Train'}), \n",
    "                        pd.DataFrame({'X':np.arange(0, self.n_epoch, int(self.n_epoch/len(self.plot_losses))), 'Y':self.plot_dev_scores, 'Score':'Dev'})], axis=0)\n",
    "    \n",
    "        plt.figure()\n",
    "        pp = sns.lineplot(data=df, x = 'X', y = 'Y', hue='Score', style=\"Score\", legend= \"brief\")\n",
    "        fig_plt.set_title(\"Score Over Time\")\n",
    "        fig_plt.set_ylabel(\"Score\")\n",
    "        fig_plt.set_xlabel(\"Epoch\")\n",
    "        return fig_plt.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "0m 12s (- 7m 54s) (25 2.5) Iter: 0/1 | Loss:0.3015\n",
      "0m 24s (- 7m 42s) (50 5.0) Iter: 0/1 | Loss:0.05357\n",
      "0m 36s (- 7m 30s) (75 7.5) Iter: 0/1 | Loss:0.02527\n",
      "0m 48s (- 7m 18s) (100 10.0) Iter: 0/1 | Loss:0.02292\n",
      "1m 0s (- 7m 5s) (125 12.5) Iter: 0/1 | Loss:0.02252\n",
      "1m 13s (- 6m 53s) (150 15.0) Iter: 0/1 | Loss:0.02236\n",
      "1m 25s (- 6m 41s) (175 17.5) Iter: 0/1 | Loss:0.02227\n",
      "1m 37s (- 6m 29s) (200 20.0) Iter: 0/1 | Loss:0.02221\n",
      "1m 49s (- 6m 17s) (225 22.5) Iter: 0/1 | Loss:0.02217\n",
      "2m 1s (- 6m 5s) (250 25.0) Iter: 0/1 | Loss:0.02214\n",
      "2m 13s (- 5m 52s) (275 27.500000000000004) Iter: 0/1 | Loss:0.02212\n",
      "2m 26s (- 5m 40s) (300 30.0) Iter: 0/1 | Loss:0.0221\n",
      "2m 38s (- 5m 28s) (325 32.5) Iter: 0/1 | Loss:0.02209\n",
      "2m 50s (- 5m 16s) (350 35.0) Iter: 0/1 | Loss:0.02208\n",
      "3m 2s (- 5m 4s) (375 37.5) Iter: 0/1 | Loss:0.02207\n",
      "3m 14s (- 4m 52s) (400 40.0) Iter: 0/1 | Loss:0.02206\n",
      "3m 26s (- 4m 39s) (425 42.5) Iter: 0/1 | Loss:0.02206\n",
      "3m 39s (- 4m 27s) (450 45.0) Iter: 0/1 | Loss:0.02205\n",
      "3m 51s (- 4m 15s) (475 47.5) Iter: 0/1 | Loss:0.02205\n",
      "4m 3s (- 4m 3s) (500 50.0) Iter: 0/1 | Loss:0.02204\n",
      "4m 15s (- 3m 51s) (525 52.5) Iter: 0/1 | Loss:0.02205\n",
      "4m 27s (- 3m 38s) (550 55.00000000000001) Iter: 0/1 | Loss:0.02204\n",
      "4m 39s (- 3m 26s) (575 57.49999999999999) Iter: 0/1 | Loss:0.02203\n",
      "4m 51s (- 3m 14s) (600 60.0) Iter: 0/1 | Loss:0.02203\n",
      "5m 4s (- 3m 2s) (625 62.5) Iter: 0/1 | Loss:0.02203\n",
      "5m 16s (- 2m 50s) (650 65.0) Iter: 0/1 | Loss:0.02203\n",
      "5m 28s (- 2m 38s) (675 67.5) Iter: 0/1 | Loss:0.02203\n",
      "5m 40s (- 2m 25s) (700 70.0) Iter: 0/1 | Loss:0.02204\n",
      "5m 52s (- 2m 13s) (725 72.5) Iter: 0/1 | Loss:0.02203\n",
      "6m 4s (- 2m 1s) (750 75.0) Iter: 0/1 | Loss:0.02202\n",
      "6m 17s (- 1m 49s) (775 77.5) Iter: 0/1 | Loss:0.02202\n",
      "6m 29s (- 1m 37s) (800 80.0) Iter: 0/1 | Loss:0.02202\n",
      "6m 41s (- 1m 25s) (825 82.5) Iter: 0/1 | Loss:0.02202\n",
      "6m 53s (- 1m 12s) (850 85.0) Iter: 0/1 | Loss:0.02202\n",
      "7m 5s (- 1m 0s) (875 87.5) Iter: 0/1 | Loss:0.02204\n",
      "7m 17s (- 0m 48s) (900 90.0) Iter: 0/1 | Loss:0.02202\n",
      "7m 30s (- 0m 36s) (925 92.5) Iter: 0/1 | Loss:0.02202\n",
      "7m 42s (- 0m 24s) (950 95.0) Iter: 0/1 | Loss:0.02202\n",
      "7m 54s (- 0m 12s) (975 97.5) Iter: 0/1 | Loss:0.02202\n",
      "<sos> trong 4 phút , chuyên gia hoá học khí quyển <unk> <unk> giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình - - hàng ngàn người đã cống hiến cho dự án này - - một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt . <eos>\n",
      "<sos> in 4 minutes , atmospheric chemist <unk> pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule . <eos>\n",
      "<sos> , with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with with <eos>\n",
      "[51.99992322921753, 52.0]\n",
      "<sos> khi tôi nói chuyện với bạn hôm nay , những người này vẫn đang ở sâu trong cái hố đó , liều mạng sống mà không có lương hay thù lao , và thường là sẽ chết . <eos>\n",
      "<sos> as i stand talking to you today , these men are still deep in that hole , risking their lives without payment or compensation , and often dying . <eos> <pad> <pad>\n",
      "<sos> , a , , , , , a , , , , , , atmospheric , atmospheric , , , , , atmospheric , atmospheric , atmospheric , atmospheric , , , atmospheric <eos>\n",
      "[8.274845153093338, 18.164138182997704, 3.0731570795178413, 2.414630737155676, 2.2490829285234213, 2.131123760715127, 1.9194171484559774, 2.190154394134879, 1.5917493607848883, 1.4424884673207998, 1.1261486019939184, 1.1183243617415428, 1.0760024450719357, 1.1778413262218237, 1.0681071355938911, 0.8021091725677252, 0.9382382538169622, 1.0624938271939754, 1.2553831674158573, 1.1043886505067348, 1.0944668632000685, 1.4517869614064693, 1.4770074840635061, 1.1576258856803179, 1.3320973180234432, 1.124908458441496, 1.1793054677546024, 1.201491441577673, 0.9713764656335115, 1.164746567606926, 1.2312633600085974, 1.101312866434455, 1.1141813155263662, 1.0012005884200335, 1.145605267956853, 1.0414774883538485, 1.0023012962192297, 1.0379956662654877, 1.09385453350842, 1.2918449752032757, 1.1321971956640482, 1.0602266490459442, 1.3152076452970505, 1.1879612114280462, 1.1196753960102797, 1.057331571355462, 1.1864753533154726, 1.2647288385778666, 1.28961774520576, 1.3421759828925133, 1.1884295381605625, 1.2613533232361078, 0.9725001491606236, 0.9807927124202251, 1.0584111269563437, 1.1887290012091398, 0.8501286879181862, 0.9725281577557325, 1.0636198408901691, 0.9551899004727602, 1.4507958814501762, 2.831280741840601, 11.986630849540234, 19.595103412866592]\n",
      "EPOCH : 999 | Train Score: 39.15991104729554 | Dev Score: 1.0599452204627795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training Complete!'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "encoder_params = {'hidden_size':256, 'num_layers':1}\n",
    "decoder_params = {'hidden_size':encoder_params['hidden_size'], 'num_layers':1, 'output_size':en.n_words}\n",
    "\n",
    "encoder = EncoderRNN(encoder_params, vi.emb, vi.learn_ids).to(device)\n",
    "encoder_optim = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "decoder = DecoderRNN(decoder_params, en.emb, en.learn_ids).to(device)\n",
    "decoder_optim = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "model = Model(encoder, decoder, encoder_optim, decoder_optim, 3)\n",
    "model.fit(train_loader, dev_loader, teacher_forcing_ratio=1.0, n_epoch=1000, print_every=25, n_grams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "2m 54s (- 26m 13s) (1 10.0) Iter: 200/1713 | Loss:3.682\n",
      "5m 48s (- 52m 19s) (1 10.0) Iter: 400/1713 | Loss:3.344\n",
      "8m 41s (- 78m 13s) (1 10.0) Iter: 600/1713 | Loss:3.251\n",
      "11m 34s (- 104m 9s) (1 10.0) Iter: 800/1713 | Loss:3.201\n",
      "14m 25s (- 129m 51s) (1 10.0) Iter: 1000/1713 | Loss:3.176\n",
      "17m 20s (- 156m 1s) (1 10.0) Iter: 1200/1713 | Loss:3.16\n",
      "20m 13s (- 181m 59s) (1 10.0) Iter: 1400/1713 | Loss:3.132\n",
      "23m 8s (- 208m 15s) (1 10.0) Iter: 1600/1713 | Loss:3.118\n",
      "EPOCH : 1 | Train Score: 1.094366405687311 | Dev Score: 2.4735624511076146\n",
      "27m 43s (- 110m 54s) (2 20.0) Iter: 200/1713 | Loss:4.849\n",
      "30m 37s (- 122m 29s) (2 20.0) Iter: 400/1713 | Loss:3.072\n",
      "33m 31s (- 134m 4s) (2 20.0) Iter: 600/1713 | Loss:3.066\n",
      "36m 24s (- 145m 39s) (2 20.0) Iter: 800/1713 | Loss:3.048\n",
      "39m 16s (- 157m 7s) (2 20.0) Iter: 1000/1713 | Loss:3.047\n",
      "42m 11s (- 168m 45s) (2 20.0) Iter: 1200/1713 | Loss:3.044\n",
      "45m 4s (- 180m 18s) (2 20.0) Iter: 1400/1713 | Loss:3.026\n",
      "47m 58s (- 191m 55s) (2 20.0) Iter: 1600/1713 | Loss:3.019\n",
      "EPOCH : 2 | Train Score: 1.0553992462920139 | Dev Score: 2.105927068707384\n",
      "52m 33s (- 122m 38s) (3 30.0) Iter: 200/1713 | Loss:4.712\n",
      "55m 27s (- 129m 23s) (3 30.0) Iter: 400/1713 | Loss:2.996\n",
      "58m 19s (- 136m 4s) (3 30.0) Iter: 600/1713 | Loss:2.993\n",
      "61m 12s (- 142m 48s) (3 30.0) Iter: 800/1713 | Loss:2.976\n",
      "64m 4s (- 149m 29s) (3 30.0) Iter: 1000/1713 | Loss:2.979\n",
      "66m 57s (- 156m 15s) (3 30.0) Iter: 1200/1713 | Loss:2.978\n",
      "69m 50s (- 162m 58s) (3 30.0) Iter: 1400/1713 | Loss:2.962\n",
      "72m 43s (- 169m 42s) (3 30.0) Iter: 1600/1713 | Loss:2.957\n",
      "EPOCH : 3 | Train Score: 0.853518981427181 | Dev Score: 1.6645004843732714\n",
      "77m 17s (- 115m 55s) (4 40.0) Iter: 200/1713 | Loss:4.618\n",
      "80m 10s (- 120m 15s) (4 40.0) Iter: 400/1713 | Loss:2.942\n",
      "83m 2s (- 124m 34s) (4 40.0) Iter: 600/1713 | Loss:2.939\n",
      "85m 55s (- 128m 53s) (4 40.0) Iter: 800/1713 | Loss:2.921\n",
      "88m 47s (- 133m 10s) (4 40.0) Iter: 1000/1713 | Loss:2.926\n",
      "91m 40s (- 137m 30s) (4 40.0) Iter: 1200/1713 | Loss:2.926\n",
      "94m 33s (- 141m 50s) (4 40.0) Iter: 1400/1713 | Loss:2.912\n",
      "97m 27s (- 146m 11s) (4 40.0) Iter: 1600/1713 | Loss:2.907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7c8ab102b5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_grams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-63b00df31ae6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, dev_data, teacher_forcing_ratio, n_epoch, print_every, n_grams)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-63b00df31ae6>\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(self, inp, inp_lens, output, out_mask, out_max)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_totals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(encoder, decoder, encoder_optim, decoder_optim, 3)\n",
    "model.fit(train_loader, dev_loader, teacher_forcing_ratio=1.0, n_epoch=10, print_every=200, n_grams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "5m 49s (- 52m 24s) (1 10.0) Iter: 400/1713 | Loss:3.485\n",
      "11m 37s (- 104m 39s) (1 10.0) Iter: 800/1713 | Loss:3.188\n",
      "17m 27s (- 157m 3s) (1 10.0) Iter: 1200/1713 | Loss:3.129\n",
      "23m 15s (- 209m 16s) (1 10.0) Iter: 1600/1713 | Loss:3.099\n",
      "EPOCH : 1 | Train Score: 0.016542484000263192 | Dev Score: 0.03486065754955129\n",
      "39m 15s (- 157m 1s) (2 20.0) Iter: 400/1713 | Loss:3.901\n",
      "45m 4s (- 180m 16s) (2 20.0) Iter: 800/1713 | Loss:3.025\n",
      "50m 53s (- 203m 33s) (2 20.0) Iter: 1200/1713 | Loss:3.021\n",
      "56m 42s (- 226m 49s) (2 20.0) Iter: 1600/1713 | Loss:3.012\n",
      "EPOCH : 2 | Train Score: 0.004849132239198011 | Dev Score: 0.018492984527430117\n",
      "72m 48s (- 169m 53s) (3 30.0) Iter: 400/1713 | Loss:3.8\n",
      "78m 37s (- 183m 28s) (3 30.0) Iter: 800/1713 | Loss:2.961\n",
      "84m 26s (- 197m 2s) (3 30.0) Iter: 1200/1713 | Loss:2.96\n",
      "90m 15s (- 210m 36s) (3 30.0) Iter: 1600/1713 | Loss:2.96\n",
      "EPOCH : 3 | Train Score: 0.0040597454846406445 | Dev Score: 0.012296856172842112\n",
      "106m 24s (- 159m 37s) (4 40.0) Iter: 400/1713 | Loss:3.742\n",
      "112m 13s (- 168m 19s) (4 40.0) Iter: 800/1713 | Loss:2.916\n",
      "118m 2s (- 177m 4s) (4 40.0) Iter: 1200/1713 | Loss:2.925\n",
      "123m 52s (- 185m 48s) (4 40.0) Iter: 1600/1713 | Loss:2.92\n",
      "EPOCH : 4 | Train Score: 0.004838951494875174 | Dev Score: 0.010326087943816837\n",
      "140m 3s (- 140m 3s) (5 50.0) Iter: 400/1713 | Loss:3.704\n",
      "145m 52s (- 145m 52s) (5 50.0) Iter: 800/1713 | Loss:2.889\n"
     ]
    }
   ],
   "source": [
    "model = Model(encoder, decoder, encoder_optim, decoder_optim, 3)\n",
    "model.fit(train_loader, dev_loader, teacher_forcing_ratio=1.0, n_epoch=10, print_every=400, n_grams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "0m 15s (- 2m 15s) (1 10.0) Iter: 0/1713 | Loss:0.01039 | TrainScore:9.301821611466174 | DevScore:10.144865992263254\n",
      "6m 18s (- 56m 42s) (1 10.0) Iter: 400/1713 | Loss:3.481 | TrainScore:3.9491317896699902 | DevScore:3.4373696280375103\n",
      "12m 21s (- 111m 10s) (1 10.0) Iter: 800/1713 | Loss:3.195 | TrainScore:2.9839270337976247 | DevScore:2.741219284529995\n",
      "18m 25s (- 165m 49s) (1 10.0) Iter: 1200/1713 | Loss:3.132 | TrainScore:1.402114597097759 | DevScore:1.476456197084048\n",
      "24m 30s (- 220m 37s) (1 10.0) Iter: 1600/1713 | Loss:3.099 | TrainScore:1.0247680801474728 | DevScore:0.937463584188316\n",
      "26m 21s (- 105m 27s) (2 20.0) Iter: 0/1713 | Loss:0.8663 | TrainScore:0.7355134314590411 | DevScore:0.7061211883251046\n",
      "32m 25s (- 129m 42s) (2 20.0) Iter: 400/1713 | Loss:3.031 | TrainScore:0.6045048829654783 | DevScore:0.8465479049353456\n",
      "38m 29s (- 153m 59s) (2 20.0) Iter: 800/1713 | Loss:3.027 | TrainScore:0.430588790903775 | DevScore:0.4009448010837915\n",
      "44m 34s (- 178m 18s) (2 20.0) Iter: 1200/1713 | Loss:3.021 | TrainScore:0.6896377234874003 | DevScore:0.6633675811526206\n",
      "50m 37s (- 202m 30s) (2 20.0) Iter: 1600/1713 | Loss:3.014 | TrainScore:0.6862591268417261 | DevScore:0.8590360894058751\n",
      "52m 29s (- 122m 27s) (3 30.0) Iter: 0/1713 | Loss:0.847 | TrainScore:1.0706205075388604 | DevScore:1.1980895360860881\n",
      "58m 34s (- 136m 40s) (3 30.0) Iter: 400/1713 | Loss:2.955 | TrainScore:0.8933152743360675 | DevScore:1.1104067516575693\n",
      "64m 39s (- 150m 51s) (3 30.0) Iter: 800/1713 | Loss:2.955 | TrainScore:1.3035661526750635 | DevScore:1.0761902035916213\n",
      "70m 43s (- 165m 0s) (3 30.0) Iter: 1200/1713 | Loss:2.964 | TrainScore:1.2228818789218265 | DevScore:1.1820538176967748\n",
      "76m 46s (- 179m 8s) (3 30.0) Iter: 1600/1713 | Loss:2.961 | TrainScore:1.261292150689597 | DevScore:1.2544234564870729\n",
      "78m 37s (- 117m 56s) (4 40.0) Iter: 0/1713 | Loss:0.8355 | TrainScore:1.2307149448351342 | DevScore:1.3087255399807294\n",
      "84m 41s (- 127m 2s) (4 40.0) Iter: 400/1713 | Loss:2.913 | TrainScore:0.952116669668053 | DevScore:1.309404800620031\n",
      "90m 47s (- 136m 10s) (4 40.0) Iter: 800/1713 | Loss:2.919 | TrainScore:0.782194995136758 | DevScore:1.200373605591051\n",
      "96m 50s (- 145m 16s) (4 40.0) Iter: 1200/1713 | Loss:2.922 | TrainScore:0.7536919047422265 | DevScore:0.47590848528524443\n",
      "102m 54s (- 154m 21s) (4 40.0) Iter: 1600/1713 | Loss:2.923 | TrainScore:0.564422205074967 | DevScore:0.6417374918349669\n",
      "104m 46s (- 104m 46s) (5 50.0) Iter: 0/1713 | Loss:0.8224 | TrainScore:0.5488775273417978 | DevScore:0.6769991895673787\n",
      "110m 49s (- 110m 49s) (5 50.0) Iter: 400/1713 | Loss:2.883 | TrainScore:0.7491739962095747 | DevScore:0.7060800130693187\n",
      "116m 55s (- 116m 55s) (5 50.0) Iter: 800/1713 | Loss:2.891 | TrainScore:0.6559042609003284 | DevScore:0.5194618643468599\n",
      "123m 1s (- 123m 1s) (5 50.0) Iter: 1200/1713 | Loss:2.895 | TrainScore:0.6017341406440795 | DevScore:0.7151994259827857\n",
      "129m 6s (- 129m 6s) (5 50.0) Iter: 1600/1713 | Loss:2.897 | TrainScore:0.6453657657492349 | DevScore:0.9587829282704871\n",
      "130m 58s (- 87m 18s) (6 60.0) Iter: 0/1713 | Loss:0.817 | TrainScore:0.9120966569518829 | DevScore:0.7723914379666267\n",
      "137m 2s (- 91m 21s) (6 60.0) Iter: 400/1713 | Loss:2.857 | TrainScore:0.5477729937141224 | DevScore:0.24552804155875\n",
      "143m 6s (- 95m 24s) (6 60.0) Iter: 800/1713 | Loss:2.869 | TrainScore:0.4263836579800939 | DevScore:0.2982386116800426\n",
      "149m 12s (- 99m 28s) (6 60.0) Iter: 1200/1713 | Loss:2.875 | TrainScore:0.44272982159833835 | DevScore:0.4719741438304421\n",
      "155m 16s (- 103m 31s) (6 60.0) Iter: 1600/1713 | Loss:2.879 | TrainScore:0.5599121256215924 | DevScore:0.597526154481686\n",
      "157m 8s (- 67m 20s) (7 70.0) Iter: 0/1713 | Loss:0.8109 | TrainScore:0.4503171070691073 | DevScore:0.7008448346717561\n",
      "163m 12s (- 69m 56s) (7 70.0) Iter: 400/1713 | Loss:2.843 | TrainScore:0.038878831444602406 | DevScore:0.0725633923411494\n",
      "169m 17s (- 72m 33s) (7 70.0) Iter: 800/1713 | Loss:2.851 | TrainScore:0.1555754166528492 | DevScore:0.22153373602868345\n",
      "175m 22s (- 75m 9s) (7 70.0) Iter: 1200/1713 | Loss:2.854 | TrainScore:0.12314243082986899 | DevScore:0.034549864461042676\n",
      "181m 28s (- 77m 46s) (7 70.0) Iter: 1600/1713 | Loss:2.862 | TrainScore:0.12158828673485515 | DevScore:0.4666607163320021\n",
      "183m 20s (- 45m 50s) (8 80.0) Iter: 0/1713 | Loss:0.8076 | TrainScore:0.41129133006437996 | DevScore:0.01740545583071127\n",
      "189m 24s (- 47m 21s) (8 80.0) Iter: 400/1713 | Loss:2.825 | TrainScore:0.01616844876759632 | DevScore:0.04092499108013422\n",
      "195m 28s (- 48m 52s) (8 80.0) Iter: 800/1713 | Loss:2.839 | TrainScore:0.17714896601933844 | DevScore:0.12149484033330571\n",
      "201m 33s (- 50m 23s) (8 80.0) Iter: 1200/1713 | Loss:2.844 | TrainScore:0.08349865818495165 | DevScore:0.21828949379249202\n",
      "207m 39s (- 51m 54s) (8 80.0) Iter: 1600/1713 | Loss:2.848 | TrainScore:0.009740611323428175 | DevScore:0.010283989409644511\n",
      "209m 31s (- 23m 16s) (9 90.0) Iter: 0/1713 | Loss:0.8022 | TrainScore:0.029196789516247938 | DevScore:0.012451155371047752\n",
      "215m 36s (- 23m 57s) (9 90.0) Iter: 400/1713 | Loss:2.814 | TrainScore:0.03378809628132957 | DevScore:0.010272967401433394\n",
      "221m 40s (- 24m 37s) (9 90.0) Iter: 800/1713 | Loss:2.825 | TrainScore:0.00957724358302013 | DevScore:0.006131045823193079\n",
      "227m 45s (- 25m 18s) (9 90.0) Iter: 1200/1713 | Loss:2.836 | TrainScore:0.1814493121761148 | DevScore:0.013607689328058767\n",
      "233m 49s (- 25m 58s) (9 90.0) Iter: 1600/1713 | Loss:2.837 | TrainScore:0.005887063337469081 | DevScore:0.014679065563555572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training Complete!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(encoder, decoder, encoder_optim, decoder_optim)\n",
    "model.fit(train_loader, dev_loader, teacher_forcing_ratio=1.0, n_epoch=10, print_every=400, n_grams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testBleuScore(data_loader, n_grams, model):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        true_outputs = []\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i, (inp, inp_lens, output, out_mask, out_max) in enumerate(data_loader):\n",
    "            if i * BATCH_SIZE >= 10000:\n",
    "                break\n",
    "            if i > 0:\n",
    "                break\n",
    "            print(' '.join([vi.id2word[int(i)] for i in inp[:,0]]))\n",
    "            print(' '.join([en.id2word[int(i)] for i in output[:,0]]))\n",
    "            true_outputs += tensorToList(output)\n",
    "\n",
    "            encoder_output, encoder_hidden = model.encoder(inp, inp_lens)\n",
    "\n",
    "            decoder_input = torch.LongTensor([[SOS_ID for _ in range(inp.size(1))]]) # appends <SOS> to beginning of decoded text\n",
    "            decoder_hidden = encoder_hidden[:,-1:,:].contiguous()\n",
    "\n",
    "            # BEAM SEARCH BELOW (size self.beam_size)\n",
    "            # candidates are stored as : (curr_scores, curr_sequences, decoder_hidden, decoder_input)\n",
    "            beam_size = 1\n",
    "            candidates = [([0 for _ in range(inp.size(1))], [[str(SOS_ID)] for _ in range(inp.size(1))], decoder_hidden, decoder_input) for _ in range(beam_size)]\n",
    "            for t in range(out_max):\n",
    "                next_candidates = []\n",
    "                next_candidate_scores = [SortedList() for _ in range(inp.size(1))] # list of sorted lists of candidate scores for each sentence\n",
    "                next_candidate_inputs = [[] for _ in range(inp.size(1))] # dict from total curr score to next candidate token for each sentence\n",
    "                next_candidate_seqs = [[] for _ in range(inp.size(1))] # dict from total curr score to next candidate sequence\n",
    "                for curr_scores, curr_seqs, decoder_hidden, decoder_input in candidates:\n",
    "                    # generate output + next hidden state given input and current hidden state of the candidate\n",
    "                    decoder_output, decoder_hidden, _ = model.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "                    topv, topi = decoder_output.topk(beam_size)\n",
    "                    for k in range(beam_size): \n",
    "                        # calculate for each sentence the next `beam_size` best possible next tokens\n",
    "                        decoder_input = torch.LongTensor([[topi[i][k] for i in range(inp.size(1))]]).to(device)\n",
    "                        for i in range(inp.size(1)):\n",
    "                            # for sentence `i`, add `topi[i][k]` as a candidate if the new score for the seq is better than the other candidates\n",
    "                            if (curr_seqs[i][-1] == EOS_ID): #don't do anything with current sequence if already is EOS\n",
    "                                continue \n",
    "                            curr_score = curr_scores[i] + topv[i][k].item()\n",
    "                            if (len(next_candidate_scores[i]) < beam_size or curr_score < next_candidate_scores[i][beam_size - 1]) and curr_score not in next_candidate_scores[i]:\n",
    "                                if len(next_candidate_scores[i]) == beam_size:\n",
    "                                    next_candidate_inputs[i] = [candidate_input for candidate_input in next_candidate_inputs[i] if candidate_input[0] != next_candidate_scores[i][beam_size - 1]] # delete candidate associated with score\n",
    "                                    next_candidate_seqs[i] = [candidate_seq for candidate_seq in next_candidate_seqs[i] if candidate_seq[0] != next_candidate_scores[i][beam_size - 1]] # delete candidate associated with score\n",
    "                                    del next_candidate_scores[i][beam_size - 1] # delete associated score\n",
    "                                next_candidate_scores[i].insort(curr_score) # insert new score in sorted order to scores lists for the i'th sentence\n",
    "                                next_candidate_inputs[i].append((curr_score, topi[i][k].item())) # insert new token value for score key for the i'th sentence\n",
    "                                next_candidate_seqs[i].append((curr_score, curr_seqs[i] + [str(topi[i][k].item())]))\n",
    "                next_candidate_scores = [[score for score in next_candidate_scores[i]] for i in range(inp.size(1))]\n",
    "                next_candidate_seqs = [[candidate_seq[1] for candidate_seq in sorted(next_candidate_seqs[i])] for i in range(inp.size(1))]\n",
    "                next_candidate_inputs = [[candidate_input[1] for candidate_input in sorted(next_candidate_inputs[i])] for i in range(inp.size(1))]\n",
    "#                 now that each best 3 sequences for each sentence is selected, create new candidates.\n",
    "                for k in range(min(len(next_candidate_inputs[0]), len(next_candidate_scores[0]), len(next_candidate_seqs[0]))):\n",
    "                    decoder_input = torch.LongTensor([[next_candidate_inputs[i][k] for i in range(inp.size(1))]])\n",
    "                    next_scores = [next_candidate_scores[i][k] for i in range(inp.size(1))]\n",
    "                    next_seqs = [next_candidate_seqs[i][k] for i in range(inp.size(1))]\n",
    "                    next_candidates.append((next_scores, next_seqs, decoder_hidden, decoder_input))                            \n",
    "                candidates = next_candidates\n",
    "            pred_outputs = [pred_out + [str(EOS_ID)] for pred_out in candidates[0][1]]\n",
    "            decoder_outputs += pred_outputs\n",
    "            print(' '.join([en.id2word[int(i)] for i in pred_outputs[0]])) \n",
    "            print(candidates[0][0])\n",
    "            \n",
    "    return corpus_bleu(decoder_outputs, true_outputs, n_grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo . <eos>\n",
      "<sos> i d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper . <eos>\n",
      "<sos> thank you re unaware effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects effects <eos>\n",
      "[28.83336627483368, 28.869981050491333]\n",
      "0.8967218816691838\n",
      "0.17956876754760742\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(testBleuScore(train_loader, 4, model))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1532582123400/work/aten/src/THC/generic/THCTensorCopy.cpp:70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mcopy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1532582123400/work/aten/src/THC/generic/THCTensorCopy.cpp:70"
     ]
    }
   ],
   "source": [
    "encoder.embedding(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
